---
index: 1
icon: creative
title: Domain 2. Design High-Performing Architectures
category: aws
editLink: false
---
## Elastic and Scalable Compute Solutions for a Workload
**워크로드를 위한 탄력적이고 확장 가능한 컴퓨팅 솔루션 식별**

솔루션의 확장성 또는 탄력성은 아키텍처에서 사용하기로 선택한 AWS 서비스와 함께 작동하도록 해당 서비스를 구성한 방법에 따라 달라질 수 있습니다.


AWS의 일부 서비스는 예를 들어 AWS Lambda와 같은 서비스는 아무 것도 할 필요 없이 자동으로 탄력적입니다. 확장 가능하고 탄력적인 서비스입니다. Lambda 함수를 초당 한 번 또는 100번 호출해야 하는 경우 간단하게 수행할 수 있습니다. AWS Lambda를 확장하기 위해 서비스를 확장하거나 아키텍처를 설계할 필요가 없습니다. 모든 AWS 서비스에 해당되는 것은 아닙니다. 그리고 이것은 디자인 결정을 내릴 때 아는 것이 중요합니다. Amazon EC2를 예로 들어 보겠습니다. Amazon EC2는 본질적으로 확장 가능하지 않은 서비스이지만 Amazon EC2를 확장 가능하고 탄력적으로 만드는 방법에는 여러 가지가 있습니다. Amazon EC2를 사용하여 솔루션을 설계하기 시작할 때 가장 먼저 고려해야 할 사항은 어떤 Amazon EC2 인스턴스 유형을 사용할 것입니까?

* 컴퓨팅, 스토리지 및 네트워킹 요구 사항에 따라 적절한 인스턴스를 선택합니다.
    * 올바른 인스턴스 유형을 선택하려면 먼저 애플리케이션에 필요한 것이 무엇인지 알아야 합니다. 시험의 경우 인스턴스 유형 선택과 관련된 질문이 있는 경우 애플리케이션 요구 사항에 대한 컨텍스트를 제공할 가능성이 높습니다.
    * 컴퓨팅, 스토리지 및 네트워킹 요구 사항에 대한 애플리케이션 리소스 요구 사항을 알고 있는 경우 Amazon EC2 인스턴스에 적합한 인스턴스 패밀리를 선택할 수 있습니까? 
    * 모든 단일 인스턴스 유형을 외울 필요는 없지만 워크로드에 대한 인스턴스 패밀리를 선택하는 것이 애플리케이션 성능과 확장성에 어떤 영향을 미칠 수 있는지 확실히 이해해야 합니다.
    * Amazon EC2 인스턴스 유형 페이지를 방문하여 다양한 인스턴스 패밀리에 대해 읽고 Amazon EC2를 사용하여 시험을 준비하는 방법을 살펴보십시오.

* 성능 요구 사항을 충족하도록 확장 가능한 적절한 아키텍처 및 서비스를 선택합니다.
    * 사용 사례를 기반으로 정의된 상황에서 어떤 AWS 서비스가 가장 확장 가능하고 성능이 좋을지 결정할 수 있어야 합니다. 
    * 예를 들어 Amazon EC2에서 백엔드 웹 서비스를 호스팅해야 하는 조직이 있고 이 웹 서비스의 사용량이 하루 종일 크게 달라진다고 가정해 보겠습니다. 이 솔루션은 가용성이 높고 탄력적이어야 합니다. 이 워크로드에 대해 어떤 유형의 아키텍처가 확장 가능한 솔루션이 될까요? 이 경우 Elastic Load Balancing 및 Amazon EC2 Auto Scaling과 함께 Amazon EC2를 사용하는 방법을 살펴보고 싶을 것입니다. 컴퓨팅 워크로드 확장에 적합한 아키텍처를 선택하는 방법을 아는 것은  중요합니다.

    * Amazon EC2가 유일한 컴퓨팅 옵션이 아니라는 점도 중요합니다. Amazon EC2와 AWS Lambda, 컨테이너 서비스를 언제 사용하고 싶은지에 대한 아키텍처 질문에 답할 수 있어야 합니다.
    * 언제 어떤 컴퓨팅 서비스를 사용할지, 각 컴퓨팅 서비스에 어떤 이점과 제한이 있는지 선택하는 데 매우 익숙해야 합니다. 
    * 컴퓨팅 제한 사항의 예는 이 과정을 작성하는 현재 AWS Lambda 함수가 한 번에 최대 15분 동안만 실행할 수 있다는 것입니다. 이것을 알면 Lambda를 언제 사용할지 여부에 대해 정보에 입각한 결정을 내리는 데 도움이 될 수 있습니다.

* 솔루션의 성능을 모니터링하는 지표를 식별합니다. 
    * 스케일링 주제를 보면. 일반적으로 Amazon CloudWatch에서 생성된 경보에 대해 조정 이벤트를 호출합니다. 이러한 경보는 메트릭이 정의된 시간 동안 특정 임계값을 초과할 때 호출됩니다. 조정을 위해 모니터링할 메트릭을 선택하는 방법을 아는 것은 중요합니다. 
    * CPU 사용률은 조정을 위해 모니터링하는 일반적인 Amazon EC2 지표입니다. 인스턴스 또는 인스턴스 그룹에 비해 CPU 사용률이 너무 높으면 인스턴스가 현재 수요를 따라갈 수 없다는 신호이며 조정 이벤트가 발생해야 합니다.
    *  사용자 지정 지표 또는 HealthyHostCount 또는 SurgeQueueLength와 같은 Elastic Load Balancing과 관련된 지표와 같이 조정에 사용할 수 있는 다른 유형의 지표도 있습니다. 그것은 실제로 상황에 따라 다르며, 척도 측정이 가장 의미가 있습니다. 
    * 확장에 사용할 수 있는 다양한 컴퓨팅 관련 서비스에서 사용할 수 있는 메트릭을 탐색하는 것이 좋습니다.

* 스터디 
* VPC는 한리전에 여러 가용영역, 서브넷궈성은 느낌상 한 가용
* vpc안에서 프라이빗 서브넷은 elb 프라이빗 안에 인스턴스
* 인스턴스 그룹 과 오토스케일링 그룹의 차이
## Elastic and Scalable Compute Solutions for a Workload: Question Walkthrough

**워크로드를 위한 확장 가능한 고성능 스토리지 솔루션 선택**

한 회사에서 사진과 비디오를 처리하는 응용 프로그램을 개발했습니다. 사용자가 사진과 비디오를 업로드하면 작업에서 파일을 처리합니다. 긴 동영상을 처리하는 데 최대 1시간이 소요될 수 있습니다. 회사는 Amazon EC2 온디맨드 인스턴스를 사용하여 웹 서버를 실행하고 작업을 처리하고 있습니다. 웹 계층과 처리 계층에는 Application Load Balancer 뒤의 Auto Scaling 그룹에서 실행되는 인스턴스가 있습니다.
피크 시간 동안 사용자는 애플리케이션이 느리고 애플리케이션이 일부 요청을 전혀 처리하지 않는다고 보고합니다. 저녁 시간에는 시스템이 유휴 상태입니다. 애플리케이션이 가장 비용 효율적인 방식으로 모든 작업을 처리하도록 솔루션 설계자는 무엇을 해야 합니까?

A, 웹 계층과 처리 계층의 Auto Scaling 그룹에서 더 큰 인스턴스 크기를 사용하십시오. 
B, 웹 계층 및 처리 계층의 Auto Scaling 그룹에 대해 Spot Instances를 사용합니다.
C, 웹 계층과 처리 계층 사이에 Amazon Simple Queue Service 표준 대기열을 사용합니다. 사용자 지정 대기열 메트릭을 사용하여 처리 계층에서 Auto Scaling 그룹을 확장합니다. 
D, EC2 인스턴스 및 Auto Scaling 그룹 대신 AWS Lambda 함수를 사용합니다. 충분한 동시 기능이 동시에 실행될 수 있도록 서비스 할당량을 늘립니다


이 문제의 경우 1) 처리하는 데 최대 1시간이 소요될 수 있는 작업이 있습니다. 따라서 중요할 수 있는 처리 질문에 대한 시간 프레임을 제공합니다. 그런 다음 2) 온디맨드 EC2 인스턴스를 사용하는 웹 서버의 현재 아키텍처와 Auto Scaling 그룹의 EC2 인스턴스에서 실행되는 처리 계층에 대한 세부 정보를 제공합니다. 이것은 컨텍스트 정보입니다. 그런 다음 해결하려는 문제 설명은 사용량이 많은 시간에 사용자가 응용 프로그램이 느리거나 때때로 작업을 처리하지 않는다는 것입니다.


마지막으로, 답변을 평가할 때 답변이 문제를 해결할 수 있는지 확인하고 싶지만 질문은 가장 비용 효율적인 답변을 요구한다는 점을 염두에 두어야 합니다. 이제 응답을 살펴보겠습니다.



C는 웹 계층과 처리 계층 사이에 Amazon Simple Queue Service 표준 대기열을 사용합니다. 그런 다음 사용자 지정 대기열 메트릭을 사용하여 Auto Scaling 그룹 및 처리 계층을 확장합니다. 이 질문은 Auto Scaling 그룹이 있는 처리 계층이 피크 시간에 작업을 완료할 만큼 충분히 빠르게 확장되지 않는 시나리오를 설정합니다. 즉, 인스턴스가 들어오는 요청 볼륨과 동기화하여 확장할 수 있도록 확장 요구 사항을 조정해야 합니다. Auto Scaling 그룹은 SQS 대기열의 시스템 로드 변경에 따라 확장할 수 있습니다. 따라서 SQS 대기열을 아키텍처에 도입하면 대기열이 특정 깊이에 도달하면 사용자 지정 메트릭을 사용하여 처리 인스턴스를 확장할 수 있습니다. 이는 메시지가 대기열에서 백업되기 시작한다는 신호입니다. 이 솔루션은 또한 때때로 최대 사용량에서 인스턴스가 요청을 삭제하고 작업을 전혀 처리하지 않는 문제를 해결합니다. SQS 대기열의 도입으로 Auto Scaling 그룹이 최대 용량에 도달하더라도 작업은 대기열에 저장되고 컴퓨팅 리소스를 사용할 수 있게 되면 처리됩니다. 

A는 웹 계층과 처리 계층의 Auto Scaling 그룹에서 더 큰 인스턴스 크기를 사용합니다. 인스턴스 크기가 클수록 처리 인스턴스의 성능이 향상됩니다. 그러나 비용도 증가합니다. 큰 인스턴스가 유휴 상태일 때 작은 인스턴스보다 더 많은 비용이 발생하기 때문에 이는 대부분 문제입니다. 그리고 우리는 이 애플리케이션을 통해 밤에 리소스가 유휴 상태라는 것을 알고 있습니다. 즉, 이 솔루션을 사용하여 발생하는 추가 비용으로 인해 올바른 응답으로 부적합합니다. 또한 인스턴스 크기의 변경은 처리를 보장할 수 없습니다. 이는 애플리케이션이 어떻게 작성되고 리소스를 얼마나 효과적으로 사용하는지에 따라 달라질 수 있습니다.

B는 웹 레이어와 프로세싱 레이어의 Auto Scaling 그룹에 스팟 인스턴스를 사용하는 것입니다. 이 응답의 경우, 언뜻 보기에는 좋은 응답처럼 보일 수 있습니다. 스팟 인스턴스는 온디맨드 인스턴스보다 비용 효율적입니다. 따라서 이것만으로도 이 응답을 선택하고 싶은 유혹을 받을 수 있습니다. 그러나 이 응답을 자세히 살펴보면 질문에서 설정한 문제가 실제로 해결되지 않는다는 것을 알 수 있습니다. 응용 프로그램은 느리게 실행되며 너무 많은 경우 요청을 삭제할 수 있습니다. 스팟 인스턴스를 사용한다고 해서 본질적으로 아키텍처를 더 확장할 수 있는 것은 아닙니다. 게다가 스팟 인스턴스와 온디맨드 인스턴스는 부팅 및 확장에 동일한 시간이 걸립니다. 따라서 하나를 다른 것으로 교체하는 것은 우리가 여기서 겪고 있는 문제를 실제로 변경하지 않습니다. 또한 스팟 인스턴스를 항상 사용할 수 있다는 보장도 없습니다. 따라서 스팟 인스턴스를 사용할 수 없고 애플리케이션이 계속해서 요청을 삭제할 가능성이 있습니다. 따라서 이것은 잘못된 답변입니다.

D는 EC2 인스턴스 및 Auto Scaling 그룹 대신 AWS Lambda 함수 사용이 있습니다. 충분한 동시 기능이 동시에 실행될 수 있도록 서비스 할당량을 늘립니다. 처리 작업을 실행하는 데 최대 1시간이 걸릴 수 있지만 AWS Lambda 함수의 런타임 제한은 15분이라는 것을 알고 있기 때문에 이는 잘못된 정보입니다. 

 디커플링 서비스, Amazon SQS 및 Amazon EC2 조정 사례와 AWS Lambda 기능에 대해 자세히 읽어보는 것이 좋습니다.
**스터디** 
SQS , SNS 차이 알기.

## High-performing and Scalable Storage Solutions for a Workload
**워크로드를 위한 확장 가능한 고성능 스토리지 솔루션 선택** 

 AWS에서 솔루션을 구축할 때 작업할 데이터를 저장하는 방법과 위치를 파악해야 할 가능성이 가장 큽니다. 이것은 간단한 작업처럼 보일 수 있지만 잠재적으로 요구 사항을 충족할 수 있는 다양한 AWS 스토리지 서비스가 있으며 올바른 것을 선택할 수 있으려면 연습이 필요합니다. 올바른 스토리지 솔루션을 선택하려면 솔루션이 확장되는 방식과 주어진 사용 사례에서 솔루션이 수행되는 방식을 평가하는 것이 포함됩니다. 예를 들어 Amazon EBS는 Amazon S3 또는 Amazon EFS와 같은 스토리지 솔루션과 완전히 다른 확장 메커니즘 및 성능 영향을 미칩니다.

* 향후 요구 사항을 수용하도록 확장 가능한 스토리지 서비스를 결정합니다

    * Amazon EBS를 파일 시스템의 스토리지로 사용하여 Amazon EC2 인스턴스에서 웹 애플리케이션을 호스팅한다고 가정해 보겠습니다. EBS 볼륨의 스토리지 용량이 부족해지기 시작하면 볼륨을 확장해야 합니다. 어떻게 합니까? 볼륨 크기를 변경해야 합니다. 이는 자동으로 발생하는 것이 아닙니다. 대신 이 수직적 확장이 일어나도록 조치를 취해야 합니다. 물론 이 작업은 자동화될 수 있지만 볼륨이 필요에 따라 더 많은 메모리를 추가하는 것은 서비스 기능에 내장된 것이 아닙니다. 이제 Amazon EFS를 사용하는 것과 비교해 보겠습니다. Amazon EFS에서 파일 시스템을 호스팅하고 있었고 스토리지를 한 번에 또는 다른 번에 수직으로 확장해야 할 것으로 예상되는 경우 해당 스토리지를 어떻게 확장할 수 있습니까? Amazon EBS의 경우처럼 수행해야 하는 작업입니까? 이 경우 Amazon EFS는 파일 시스템에서 파일을 추가하거나 제거할 때 자동으로 확장 및 축소됩니다.

    * 이러한 유형의 서비스 지식은 스토리지 확장에 필요한 운영 지원이 가장 적은 스토리지 솔루션을 선택하라는 시험에서 질문을 받는 경우에 유용할 수 있습니다. 또한 미래의 스토리지 요구 사항에 따라 어떤 스토리지 솔루션이 가장 적합한지 결정할 수 있어야 합니다. 데이터는 일반적으로 정적이지 않습니다. 시간이 지남에 따라 애플리케이션을 작동하면 데이터가 축적될 가능성이 가장 높으며 아키텍처 결정을 내릴 때 해당 데이터 축적 속도를 고려해야 합니다. 현재 3TB의 데이터 스토리지가 필요한 애플리케이션이 있지만 향후 5년 동안 100TB의 데이터 스토리지가 필요한 애플리케이션이 있다고 가정해 보겠습니다. 이것은 솔루션을 선택할 때 고려해야 할 사항입니다. 이는 또한 스토리지 솔루션의 용량에 대한 일반적인 상한을 알고 있어야 함을 의미합니다. 이는 향후 데이터 저장 요구 사항에 적합한 서비스를 선택하는 데 도움이 됩니다.

* 성능 요구 사항을 충족하는 스토리지 서비스 및 구성을 선택합니다.
    * 확장성 측면에서 AWS 스토리지 솔루션을 비교하는 것 외에도 성능을 기반으로 상황에 가장 적합한 솔루션을 결정할 수 있어야 합니다. 예를 들어 데이터를 처리하는 애플리케이션이 있고 이 애플리케이션은 데이터를 읽는 데 매우 짧은 대기 시간이 필요하다고 가정해 보겠습니다. 이 막연한 시나리오를 기반으로 짧은 대기 시간 요구 사항에 가장 적합한 AWS 스토리지 서비스를 생각해야 합니다. Amazon EBS 볼륨은 지연 시간이 매우 짧지만 성능 정도는 구성할 수 있습니다. 다양한 유형의 EBS 볼륨과 각 유형이 사용 사례 및 IOPS를 기반으로 하는 성능에 대해 잘 알고 있어야 합니다. EBS 볼륨에 대한 올바른 구성을 선택하면 성능에 큰 영향을 미칠 수 있으므로 솔루션을 설계할 때 이러한 구성을 인식하는 것이 중요합니다

    * 성능에 영향을 줄 수 있는 스토리지 서비스에 대한 구성이 많이 있으며 각 서비스의 주요 성능 구성에 대해 잘 알고 있어야 합니다.
     예를 들어 Amazon S3를 사용하여 솔루션을 설계할 때 데이터 업로드 또는 데이터 검색의 성능을 개선할 수 있는 방법을 고려하라는 요청을 받을 수 있습니다. 데이터 업로드 또는 전송의 경우 Amazon S3에 대한 기본 API 호출 또는 CLI 명령이 무엇인지 알고 있어야 하며 멀티파트 업로드 사용에 익숙해야 합니다. 또한 더 성능이 좋은 업로드를 위한 Amazon S3 Accelerator 또는 더 빠른 데이터 검색을 위한 Amazon CloudFront를 통한 캐싱과 같은 기능이 있어 설계 결정을 내리고 시험 문제에 답하는 데 도움이 될 수 있습니다.


공부할 때 다음 사항에 중점을 두어야 합니다. 현재 및 미래의 스토리지 요구 사항을 수용하도록 확장할 수 있는 사용할 스토리지 서비스를 결정할 수 있고 다양한 상황에서 성능 요구 사항을 충족하는 AWS 서비스 및 구성을 선택할 수 있습니다. 이러한 주제에 대해 자세히 알아보려면 AWS 설명서와 백서를 자세히 살펴보는 것이 좋습니다.

* 스터디 
S3 
* Basic API calls 
* Multipart uploads
* amazon S3 Accelerator : 리전끼리 사용할 때 
* Caching with Amazon ClouldFront 

엣지 로케이션
ClouldFront  CDN이용. 
리전과 다른개념,빠른제공위해 더 많이 만들려고 한다.  
## High-performing and Scalable Storage Solutions for a Workload: Question Walkthrough

솔루션 설계자는 Amazon S3 버킷에 업로드할 많은 수의 비디오 파일을 받았습니다. 파일 크기는 100~500MB입니다. 솔루션 설계자는 또한 실패한 업로드 시도를 쉽게 재개하기를 원합니다. 솔루션 설계자는 어떻게 최단 시간에 업로드를 수행해야 합니까?

A. 각 파일을 5MB 부분으로 분할합니다. 개별 부품을 업로드하고 S3 멀티파트 업로드를 사용하여 부품을 완전한 객체로 병합합니다. 
B. AWS CLI를 사용하여 aws s3 cp 명령으로 개별 객체를 Amazon S3 버킷에 복사합니다. 
C. Amazon S3 콘솔에서 Amazon S3 버킷을 선택합니다. S3 버킷을 업로드하고 항목을 버킷으로 끌어다 놓습니다. 
D. SFTP 및 AWS Transfer Family를 사용하여 파일을 업로드합니다. 이제 질문과 응답을 검토할 수 있도록 일시 중지하겠습니다.

이 질문에 집중해야 할 부분은 1) 우리가 알고 있는 파일이 S3에 업로드되고 있다는 사실입니다.  2) 또한 100~500MB의 파일 크기를 제공합니다.  일반적으로 이와 같은 숫자나 세부사항이 제공될 때 주의를 기울입니다. 왜냐하면 이것이 파일 크기가 중요하다는 것을 의미할 가능성이 높기 때문입니다. 해결해야 할 문제는 3)솔루션 설계자가 실패한 업로드 시도를 쉽게 재개해야 한다는 것입니다. 마지막으로 4) 시간이 가장 적게 소요되는 솔루션을 묻는 질문입니다. 

답은 B입니다. AWS CLI를 사용하여 aws s3 cp 명령으로 개별 객체를 Amazon S3 버킷에 복사합니다. 일반적으로 객체 크기가 100MB에 도달하면 단일 작업으로 객체를 업로드하는 대신 멀티파트 업로드 사용을 고려해야 합니다. 멀티파트 업로드를 사용하면 처리량이 향상될 수 있으며 네트워크 오류로 인해 다시 시작하는 개체를 빠르게 복구할 수도 있습니다.  실패한 업로드 시도를 쉽게 재개할 수 있다고 말했으며 멀티파트 업로드가 이를 도와줍니다. 이제 명령줄과 cp 명령을 사용하려는 이유는 aws s3 명령이 파일 크기에 따라 멀티파트 업로드 및 다운로드를 자동으로 수행하기 때문입니다. 즉, 이 옵션이 문제를 해결하고 명령줄이 이미 멀티파트 업로드 부분을 수행하기 때문에 해결하는 데 시간이 거의 걸리지 않습니다.

A는 각 파일을 5MB 부분으로 분할합니다. 개별 부품을 정상적으로 업로드하고 S3 멀티파트 업로드를 사용하여 부품을 완전한 객체로 병합합니다. S3의 멀티파트 업로드는 100MB를 초과하는 객체에 권장되기 때문에 이것은 올바르지 않습니다. 따라서 객체를 5MB 부분으로 분할할 필요가 없으며 업로드하기 전에 객체가 여러 부분으로 분할되었기 때문에 S3의 객체를 원래 크기로 재조립해야 합니다. 이것은 또한 cp 명령을 사용하는 것보다 더 많은 시간이 걸립니다. 
C는 Amazon S3 콘솔에서 Amazon S3 버킷을 선택합니다. S3 버킷을 업로드하고 항목을 버킷으로 끌어다 놓습니다. 관리 콘솔에서 S3로 파일을 업로드하면 네트워크 문제로부터 보호되지 않거나 자동으로 멀티파트 업로드가 수행되지 않기 때문에 이것은 올바르지 않습니다. 따라서 이것은 줄기에 제시된 문제를 해결하지 못합니다.
D는 SFTP 및 AWS Transfer Family로 파일 업로드가 있습니다. 이 옵션은 SFTP를 통해 파일을 업로드할 수 있지만 파일 업로드를 쉽게 다시 시작하는 문제를 해결하지 못하기 때문에 올바르지 않습니다. 또한 이 옵션을 사용하려면 명령줄과 복사 명령을 사용하는 것보다 더 많은 작업과 시간이 필요합니다.


## High-performing Networking Solutions for a Workload
**워크로드를 위한 고성능 네트워킹 솔루션 선택**

* 성능 요구 사항을 충족하는 데 적절한 AWS 연결 옵션을 선택합니다
    * AWS 솔루션 설계자가 되려면 절대적인 네트워킹 전문가가 되어야 한다는 의미는 아니지만, 정보에 입각한 결정을 내리고 기본적인 문제 해결을 수행하려면 AWS 네트워킹 서비스 및 솔루션에 대해 충분히 알고 있어야 합니다. 예를 들어, 하이브리드 모델을 따르는 것은 AWS와 함께 작업할 때 매우 일반적입니다. 즉, 회사에는 AWS에서 호스팅되는 솔루션과 함께 운영되는 온프레미스 데이터 센터가 있습니다. 온프레미스 데이터 센터와 AWS 리소스는 종종 시스템 간에 데이터와 메시지를 전송하기 위해 개인적으로 통신하는 방법이 필요합니다. AWS Managed VPN 또는 AWS Direct Connect와 같은 서비스를 사용하여 AWS 리소스를 온프레미스, 데이터 센터 리소스에 비공개로 연결할 수 있습니다. 하이브리드 배포에 대한 데이터 볼륨, 규정 준수 표준 및 성능 요구 사항을 감안할 때 적절한 연결 옵션을 선택할 수 있어야 합니다. VPN 또는 Direct Connect 연결 유형에 대한 사용 사례 간에 미묘한 차이가 있을 수 있습니다. 그리고 VPN 연결과 AWS Direct Connect 연결의 성능 및 처리량 기능에 익숙해져야 아키텍처 결정을 내릴 때 적절하게 비교하고 대조할 수 있습니다.

    * AWS Managed VPN 및 AWS Direct Connect 외에도 VPN 또는 Direct Connect와 함께 사용하여 여러 VPC를 원격 네트워크에 연결할 수 있는 AWS Transit Gateway와 같은 서비스에 익숙해야 합니다. 또한 Transit Gateway의 작동 방식, 사용 사례 및 네트워크 피어링 솔루션을 단순화할 수 있는 방법을 알아야 합니다. 상위 수준에서 알아야 할 또 다른 서비스는 AWS CloudHub로, 네트워크 연결을 위한 허브 및 스포크 모델을 생성하는 데도 도움이 될 수 있습니다. 원격 네트워크를 AWS에 연결하는 것 외에도 VPC 간에 연결을 생성하는 방법도 알아야 합니다. 한 VPC의 애플리케이션이 다른 VPC 또는 다른 AWS 계정에서 호스팅되는 애플리케이션과 함께 메시지 또는 데이터를 수신 및 전송할 수 있도록 이 작업을 수행할 수 있습니다. VPC를 서로 연결하기 위한 아키텍처를 선택하고 솔루션을 비교하는 것도 이 시험에서 중요한 지식입니다. 따라서 VPC peering, AWS Transit Gateway, AWS PrivateLink 및 AWS Managed VPN과 같은 서비스의 사용 사례, 요구 사항 및 제한 사항에 대해 알고 있어야 합니다.
    * 스터디 보기

* AWS 퍼블릭 서비스에 대한 연결을 최적화하는 데 적절한 기능을 선택합니다.

    * 프라이빗 연결을 통해 온프레미스 데이터 센터를 AWS에 연결하는 것 외에도 적절한 기능을 선택하여 퍼블릭 서비스에 대한 AWS 연결을 최적화할 수 있어야 합니다. 연결을 생성하거나 퍼블릭 AWS 리소스에 요청을 보낼 수 있는 다양한 방법이 있으며 AWS에 대한 연결을 최적화하기 위해 적절한 기능을 선택할 수 있어야 합니다. 예를 들어 두 개의 서로 다른 리전에 호스팅된 웹 사이트가 있고 해당 웹 사이트에 액세스하는 최종 사용자와 지리적으로 가장 가까운 리전에 트래픽을 보내려고 한다고 가정해 보겠습니다. 트래픽을 올바른 리전으로 라우팅하는 데 사용할 AWS 서비스 또는 기능은 무엇입니까? 이것을 아는 열쇠는 Amazon Route 53이 어떻게 작동하는지, 다양한 라우팅 정책과 그들이 제공하는 사용 사례를 아는 것입니다. 이 예에서는 Amazon Route 53 지리 근접 라우팅 정책을 사용합니다. 이 시험을 준비할 때 Amazon Route 53을 자세히 살펴보는 것이 좋습니다.
    라우팅 정책 외에도 Amazon Route 53의 기능과 이를 사용하여 솔루션을 개발하는 방법을 확실히 이해하고 있어야 합니다. 여기에는 생성할 수 있는 레코드 유형과 일반적으로 Route 53을 사용해야 하는 이유에 대한 이해가 포함됩니다. 또한 
    애플리케이션의 네트워크 성능을 향상시킬 수 있고 네트워크 성능을 위해 AWS 솔루션을 최적화할 때 고려할 수 있는 서비스인 AWS Global Accelerator에 대해 알아보는 것이 좋습니다. 

*  성능 이점을 제공하는 엣지 캐싱 전략을 결정합니다.
    네트워크 성능을 개선할 수 있는 또 다른 방법은 Amazon CloudFront와 같은 서비스를 사용하여 AWS 엣지 로케이션을 활용하여 최종 사용자에게 더 가까운 자산 캐싱을 고려하는 것입니다. Amazon CloudFront의 사용 사례와 작동 방식 및 사용 이점에 대한 심층적인 지식이 있어야 합니다.

*  마이그레이션 및/또는 수집에 적합한 데이터 전송 서비스를 선택합니다.

    * 네트워크 성능에 대한 또 다른 주제는 데이터 마이그레이션 또는 수집을 위해(inject 영어표현다시봄)적절한 데이터 전송 서비스를 선택할 수 있어야 한다는 것입니다. 
    * 적절한 솔루션을 선택할 수 있도록 여러 데이터 전송 서비스 또는 AWS로 데이터를 전송할 수 있는 방법에 대해 잘 알고 있어야 합니다. 
    * AWS DataSync, AWS Snow Family, AWS Transfer Family, AWS Database Migration Service 및 기타 아키텍처를 편안하게 설계할 수 있는 기타가 있습니다. 데이터의 양, 데이터 유형, 데이터 마이그레이션의 소스 및 대상에 따라 하나의 서비스가 다른 서비스보다 더 적합할 수 있습니다. 따라서 데이터 전송 서비스와 마이그레이션 서비스 간의 기능 및 성능 차이를 아는 것이 중요합니다. 
```
 AWS DataSync:
 AWS DataSync는 온프레미스 스토리지 시스템 간 데이터 이동을 단순화, 자동화 및 가속화하는 온라인 데이터 전송 서비스입니다.AWS스토리지 서비스 및 그 사이AWS스토리지 서비스. DataSync다음 사이에 데이터를 복사할 수 있습니다
  AWS Snow Family :AWS Snow 패밀리는 네트워크에 대한 의존 없이 대량 데이터를 클라우드 안팎으로 마이그레이션할 수 있도록 지원하는 물리적 디바이스의 모음으로서, 이
   AWS Transfer :
   Family AWS Database Migration Service
```

이 비디오에서 제가 언급한 주제 중 일부가 낯설더라도 걱정하지 마십시오. AWS 설명서에서 이러한 주제에 대해 자세히 읽고, 자신의 AWS 계정에서 몇 가지 실험과 구축을 수행하고, 아직 이해하지 못한 개념에 집중하면 됩니다.

스터디 
* 1. AWS Managed VPN 와 AWS Direct Connect
* 온프레미스 - aws서비스 연결
AWS Managed VPN : 인터넷이용, 느리다. 
AWS Direct Connect : 이더넷 광렌, 전용선 빠르다. 구축비용 크다.

* 2. AWS networking connectivity services 
    - aws Managed VPC
    - AWX Dorect Connect
    * AWS Transit Gateway : 각 커넥션 상위 계층으로 모든걸 관리하는 역할??, 
    Transit Gateway는 Virtual Private Cloud(VPC)와 온프레미스 네트워크 간의 트래픽에 대한 리전별 가상 라우터 역할을 합니다
    * AWS VPN CloudHub
    : VPN만 가능
    : 일대다만 가능 (온프레미스 다.
    )
    : 허브앤 스포크
    : 여러 지점과 기존 인터넷 연결이 있고 이러한 원격 사무실 간의 기본 또는 백업 연결을 위해 잠재적으로 저렴한 허브 및 스포크 모델을 구현하려는 경우 이 접근 방식을 사용하십시오.
* 3. Connectivity beetween VPCs
VPC peering,   
AWS Transit Gateway,  
AWS PrivateLink  : 내가통제하지 않는 aws 서비스를 붙일 때account 
AWS Managed VPN
* Hub and Spoke
## High-performing Networking Solutions for a Workload: Question Walkthrough

 한 대규모 국제 회사에 AWS Organizations에 관리 계정이 있고 그들이 운영하는 각 국가에 대해 50개 이상의 개별 계정이 있습니다. 각 국가 계정에는 기능 부서용으로 설정된 VPC가 4개 이상 있습니다. 계정 간에 높은 신뢰가 있고 모든 VPC 간의 통신이 허용되어야 합니다. 전체 글로벌 조직의 각 개별 VPC는 ​​계정과 다른 모든 계정에 공유 서비스를 제공하는 VPC에 액세스해야 합니다. 구성원 계정이 운영 오버헤드를 최소화하면서 공유 서비스 VPC에 액세스하려면 어떻게 해야 합니까? 

A, 공유 서비스 VPC의 프라이빗 IP 주소 대상으로 Application Load Balancer를 생성합니다. ALB에 대한 인증 기관 권한 부여 레코드를 Route 53에 추가합니다. 공유 서비스에 대한 모든 요청을 해당 CAA 레코드에 대한 VPC 라우팅 테이블로 지정합니다.
B, 각 VPC와 공유 서비스 VPC 간에 피어링 연결을 생성합니다. 
C, 공유 서비스 VPC의 AZ에 걸쳐 Network Load Balancer를 생성합니다. IAM에서 서비스 소비자 역할을 생성하고 엔드포인트 연결 수락을 자동 수락으로 설정합니다. 각 디비전 VPC에 소비자 엔드포인트를 생성하고 NLB를 가리킵니다. 
D, 각 VPC와 공유 서비스 VPC 간에 VPN 연결을 생성합니다. 이제 질문과 응답을 검토할 수 있도록 일시 중지하겠습니다.

문제에서 1) 50개가 넘는 여러 AWS 계정이 있습니다. 2) 이러한 계정의 VPC가 공유 서비스 계정의 리소스에 액세스해야 함을 알 수 있습니다. 그런 다음 질문은 3) AWS 계정이 가장 적은 운영 오버헤드로 또는 기본적으로 운영에 가장 적은 양의 작업이 필요한 공유 서비스 VPC에 액세스할 수 있는 방법을 묻습니다. 

답은 C입니다. 공유 서비스 VPC의 AZ에 걸쳐 Network Load Balancer 생성입니다. IAM에서 서비스 소비자 역할을 생성하고 엔드포인트 연결 수락을 자동 수락으로 설정합니다. 각 디비전 VPC에 소비자 엔드포인트를 생성하고 NLB를 가리킵니다. 이제 이를 올바르게 수행하기 위한 핵심은 VPC 피어링을 사용하는 것보다 AWS PrivateLink 연결을 설정하는 것이 더 적절하다는 것을 아는 것입니다. 하나 이상의 소비자 VPC가 (service-provider)서비스 제공자 VPC의 특정 서비스 또는 인스턴스 세트에 단방향 액세스를 허용하려는 클라이언트-서버 설정이 있는 경우 AWS PrivateLink를 사용합니다. 문제의 시나리오 설정에는 공유 서비스에 액세스해야 하는 여러 소비자가 있으므로 사용 사례가 적합합니다.

그런 다음 두 번째로 알아야 할 사항은 PrivateLink 연결을 설정하는 방법입니다. 이렇게 하려면 
1. Network Load Balancer를 생성하고
2.  IAM에서 서비스 소비자 역할을 생성하고, 
3. 공유 서비스 VPC에서 엔드포인트 연결을 설정하고, 자동 수락으로 설정하고
4. 공유 액세스를 시도하는 각 VPC에서 소비자 엔드포인트를 생성합니다. 
5. VPC를 선택한 다음 공유 서비스 VPC의 NLB를 가리킵니다. 이것이 VPC 간에 PrivateLink 연결을 설정하는 방법입니다. 

A, 공유 서비스 VPC의 사설 IP 주소 대상으로 Application Load Balancer 생성부터 잘못된 응답을 검토해 보겠습니다. ALB에 대한 인증 기관 권한 부여 레코드를 Route 53에 추가합니다. VPC 라우팅 테이블의 공유 서비스에 대한 모든 요청이 해당 CAA 레코드를 가리키도록 합니다.이 대답은 거의 실현 가능한 것처럼 보이지만 CAA 레코드는 도메인 또는 하위 도메인에 대한 인증서를 발급할 수 있는 인증 기관을 지정합니다. 따라서 이러한 유형의 기록은 이 시나리오에서 실제로 도움이 되지 않으므로 답이 아닙니다.

B, 각 VPC와 공유 서비스 VPC 간에 피어링 연결을 생성하는 것입니다.. VPC가 연결할 수 있는 간단한 솔루션입니다. 그렇다면 이것이 잘못된 이유는 무엇입니까? 글쎄요, VPC 피어링 연결은 피어링 연결 수에 제한이 있습니다. 하나의 VPC는 ​​최대 125개의 피어링 연결을 허용할 수 있습니다. 그리고 질문을 보면 계정당 4개의 VPC가 있는 50개가 넘는 계정이 있음을 알 수 있습니다. 이렇게 하면 필요한 피어링 연결 수가 125개가 넘으므로 공유 서비스 VPC가 이러한 피어링 연결 요청을 모두 수락할 수 없습니다. 그래서 이것은 오답입니다.

D, 각 VPC와 공유 서비스 VPC 간에 VPN 연결을 생성합니다. 이 모든 VPC 간에 VPN 연결을 생성하고 관리할 수 있지만 기술적으로 아무런 문제가 없지만 이러한 모든 VPN 연결을 유지 관리하고 운영해야 하므로 PrivateLink 연결을 다음과 같이 설정하는 것보다 운영 오버헤드가 더 큽니다. 응답 C에 설명되어 있습니다.

 이 항목을 제대로 이해하지 못한 경우 VPC 간에 연결을 설정하는 방법을 더 자세히 살펴봐야 합니다. 또한 매우 일반적인 공유 서비스 VPC가 있는 시나리오를 포함하여 다중 계정 설정을 위한 네트워킹 전략을 설계하는 방법을 읽어야 합니다.

## High-performing Database Solutions for a Workload
**워크로드를 위한 고성능 데이터베이스 솔루션 선택**

AWS에는 많은 데이터베이스 솔루션이 있으며 각각을 언제 사용해야 하는지 알기가 까다로울 수 있습니다. 시험의 경우 주어진 사용 사례에서 사용할 데이터베이스 서비스를 식별하는 것보다 더 깊은 지식을 가지고 있어야 합니다. 비관계형 데이터베이스, 관계형 데이터베이스, 그래프 데이터베이스 등에 사용할 AWS 서비스를 식별할 수 있어야 합니다.

* 성능 요구 사항을 충족하는 적합한 데이터베이스 서비스를 선택합니다.

 이러한 서비스가 어떻게 작동하고 작동하는지에 대해 더 많이 알고 있어야 하며 성능 요구 사항을 충족하는 적절한 데이터베이스 서비스를 선택할 수 있어야 합니다.  관계형 데이터베이스가 필요합니까? Amazon RDS는 고성능 데이터베이스일 수 있지만 한 자릿수 밀리초 응답 시간이 필요한 사용 사례가 있는 경우 Amazon DynamoDB가 해당 솔루션에 더 나은 선택일 것입니다.
또 다른 예는 Amazon Aurora 및 Amazon RDS와 같은 데이터베이스 간의 성능 차이를 아는 것입니다. 주어진 시나리오에 가장 적합한 데이터베이스를 선택할 수 있도록 Amazon Aurora와 Amazon RDS의 성능 및 스토리지 제한 사항을 연구하는 것이 좋습니다. Amazon RDS에는 성능 요구 사항에 맞게 선택할 수 있는 다양한 스토리지 유형이 있습니다. 범용 SSD, 프로비저닝된 IOPS 또는 마그네틱 중에서 선택할 수 있습니다. 이러한 각 스토리지 유형에 대한 사용 사례를 이해하는 것이 좋습니다.

이는 데이터베이스용 솔루션을 선택할 때 선택할 수 있는 한 가지 예입니다. AWS 데이터베이스 서비스에 대한 성능에 영향을 미치는 다양한 구성을 알고 
사용 사례 및 성능 요구 사항에 가장 적합한 서비스 또는 기능을 선택하는 것이 중요합니다.

* 적절한 데이터베이스 조정 전략(확장전략?)을 선택합니다. 
 확장 요구 사항을 충족하는 적절한 확장 전략을 선택할 수도 있어야 합니다. 예를 들어 Amazon DynamoDB는 내부적으로 스토리지를 자동으로 확장하지만 테이블 처리량의 확장은 사용자가 제어합니다. 처리량 용량을 프로비저닝하거나 처리량에 대해 Auto Scaling을 사용할 수 있습니다. 주어진 사용 사례에서 각각을 언제 사용해야 하는지 아는 것은 시험에 대해 알아야 할 지식 유형입니다.

다른 데이터베이스 서비스는 기본 스토리지에 대해 스토리지 Auto Scaling을 사용할 수 있도록 하는 Amazon RDS와 같이 다르게 확장되지만 CPU 사용량과 같은 항목에 맞게 확장하려면 DB 인스턴스를 업데이트해야 합니다. 적절한 데이터베이스 확장 전략을 선택하는 것은 사용 중인 데이터베이스 유형과 제시된 시나리오에 따라 다릅니다. 따라서 AWS 데이터베이스 서비스가 확장 또는 축소되는 방식에 대해 연구하고 있는지 확인하십시오.

* 성능 향상을 위해 데이터베이스 캐싱이 필요한 시점을 결정합니다 
성능 향상을 위해 데이터베이스 캐싱이 필요한 시기를 결정할 수 있어야 합니다. 때로는 확장을 원하지 않지만 여전히 성능 이점을 원하고 데이터를 캐싱하여 데이터베이스 읽기에 대해 이를 수행할 수 있습니다. 데이터베이스 서비스마다 익숙해져야 하는 캐싱 기능이 다릅니다. 그런 다음 캐싱을 위해 애플리케이션과 함께 사용하거나 캐싱을 위해 데이터베이스와 함께 사용할 수 있는 Amazon ElastiCache와 같은 서비스가 있습니다. Amazon ElastiCache를 사용하여 캐싱 패턴 및 아키텍처에 대해 읽어보는 것이 좋습니다. 


다양한 AWS 데이터베이스 서비스가 있습니다. 그리고 그 이유는 각 데이터베이스가 특별히 제작되었기 때문입니다. 이는 특정 사용 사례를 염두에 두고 제작되었음을 의미합니다. 따라서 모든 단일 사용 사례에 대해 동일한 데이터베이스를 사용하지는 않습니다. 일부는 사용 사례를 고려할 때 다른 것보다 성능이 뛰어납니다. 그리고 때때로 데이터베이스는 예를 들어 그래프 데이터베이스인 Amazon Neptune과 같이 고도로 전문화되어 있습니다. AWS 데이터베이스 서비스의 목적이 무엇인지 높은 수준에서 알아야 합니다. 정확히 왜 만들어졌습니까? 이 질문에 답하고 작동 방식과 구성 방식에 대해 자세히 알아보면 도움이 됩니다.

## High-performing Database Solutions for a Workload: Question Walkthrough
회사는 추가 처리를 위해 풍력 터빈의 기상 조건 및 풍속을 포함한 센서 IoT 데이터를 AWS 클라우드로 보내는 분산 애플리케이션을 구축하고 있습니다. 데이터의 특성이 spiky(뾰족하기?) 때문에 애플리케이션을 확장할 수 있어야 합니다. 스트리밍 데이터를 키-값 데이터베이스에 저장한 다음 변환, 분석 및 다양한 조직 데이터 세트와 결합하여 의미 있는 통찰력을 도출하고 예측할 수 있는 중앙 데이터 레이크로 보내는 것이 중요합니다. 최소한의 운영 오버헤드로 비즈니스 요구 사항을 충족할 수 있는 솔루션 조합은 무엇입니까? 2개를 선택합니다.

A, Amazon Kinesis를 구성하여 스트리밍 데이터를 Amazon S3 데이터 레이크로 전송합니다. 
B, Amazon DocumentDB를 사용하여 IoT 센서 데이터를 저장합니다. 
C, 스트리밍 데이터를 Amazon S3로 전달하는 AWS Lambda 함수를 작성합니다. 
D, Amazon DynamoDB를 사용하여 IoT 센서 데이터를 저장하고 DynamoDB 스트림을 활성화합니다. 
E, Amazon Kinesis를 사용하여 스트리밍 데이터를 Amazon Redshift로 전송하고 Redshift Spectrum을 활성화합니다.


저는 즉시 1) 데이터가 spiky하다는 문구와 키-값 데이터베이스에 데이터를 저장해야 할 필요성에 집중했습니다. 2) 그런 다음 분석을 위해 이 데이터를 데이터 레이크로 보내야 한다는 사실에 집중합니다. 3) 마지막으로 운영 오버헤드가 최소화된 솔루션을 찾아야 하고 4) 두 가지 답변을 선택해야 한다는 사실을 확인했습니다. 


키는 A와 D입니다. 

먼저 DynamoDB가 자동으로 확장되고 급증하는 액세스 패턴을 처리할 수 있는 키-값 데이터베이스라는 사실을 아는 것은 이 질문을 올바르게 이해하는 데 필수적입니다. 
DynamoDB는 오버헤드 없이 쉽게 확장되고 키-값 데이터를 테이블에 쉽게 저장할 수 있기 때문에 센서 데이터를 저장하는 데 탁월한 선택입니다. 그런 다음 고려해야 할 두 번째 사항은 DynamoDB 테이블의 각 항목이 데이터 레이크에도 전송되도록 하는 방법입니다. 여기에서 DynamoDB 스트림이 제공됩니다. DynamoDB 스트림은 스트림의 DynamoDB 테이블에 있는 데이터에 대한 항목 수준 변경 사항을 캡처합니다. 변경 사항이 스트림에 포함되면 해당 변경 사항을 처리하는 솔루션을 만들거나 해당 변경 사항을 데이터 레이크와 같은 다른 데이터 저장소에 복제할 수 있습니다.
따라서 응답 D, Amazon DynamoDB를 사용하여 IoT 센서 데이터 저장 및 DynamoDB 스트림 활성화가 올바른 응답입니다. 그렇다고 전체 문제가 해결되는 것은 아닙니다. 우리의 사용 사례에서는 이제 해당 데이터를 데이터 레이크로 보낼 솔루션을 찾아야 합니다. 
여기에서 답변 A, Amazon Kinesis 구성, 스트리밍 데이터를 Amazon S3 데이터 레이크로 전송합니다. 데이터를 처리하거나 DynamoDB Streams로 전달하도록 Amazon Kinesis를 구성할 수 있으며 Kinesis는 Amazon S3로 데이터를 전달할 수 있습니다. Amazon S3는 데이터 레이크를 호스팅하는 데 사용하는 매우 일반적인 서비스입니다. 따라서 이 세 가지 서비스가 통합되어 있고 모두 서버가 없다는 것을 알고 있는 이 솔루션은 문제를 해결할 뿐만 아니라 최소한의 운영 오버헤드도 필요로 합니다.

B는 Amazon DocumentDB를 사용하여 IoT 센서 데이터를 저장합니다. DocumentDB는 키-값 데이터베이스가 아니기 때문에 이것은 올바르지 않습니다. 
C는 스트리밍 데이터를 Amazon S3에 전달하는  AWS Lambda 함수 작성입니다. 이제 이 작업을 수행하고 데이터가 DynamoDB 스트림에 추가될 때 실행할 Lambda 함수를 호출할 수 있기 때문에 이것은 약간 까다롭습니다. 이것은 완전히 작동할 수 있습니다. 그러나 문제는 이 작업을 수행하기 위해 Kinesis를 사용하는 것보다 더 많은 운영 오버헤드가 필요하다는 것입니다. Lambda 함수를 작성하려면 일부 사용자 지정 코드가 필요하기 때문에 이는 올바르지 않기 때문입니다.
E는 Amazon Kinesis를 사용하여 스트리밍 데이터를 Amazon Redshift로 전송하고 Redshift Spectrum을 활성화합니다. Kinesis를 사용하여 Redshift에 데이터를 전달할 수도 있지만 Amazon S3에서는 분석을 위해 다양한 소스의 데이터를 쉽게 결합할 수 있기 때문에 Amazon S3가 이 시나리오에서 데이터 레이크에 더 나은 선택이기 때문에 이 역시 잘못된 것입니다. 운영 오버헤드가 적습니다.


## Design High-performing Architectures: Close

이 도메인을 마무리하고 AWS 솔루션 아키텍트로 일할 때 고성능 아키텍처를 설계하는 방법에 대해 생각하고 검토해야 할 주제 유형을 검토하겠습니다. 시험. AWS에서 고성능 솔루션을 설계할 때 고려해야 할 몇 가지 주요 계층이 있습니다. 컴퓨팅 계층, 스토리지 계층, 데이터베이스 계층 및 네트워킹 계층이 있습니다. 물론 보안 및 인증과 같은 다른 사항도 있지만 지금은 이 4가지 계층에만 집중해 보겠습니다.

컴퓨팅의 경우 컴퓨팅 선택을 사용 사례와 일치시키는 것이 중요하며 그 반대는 아닙니다. 이것은 고성능 컴퓨팅 워크로드 설계의 큰 부분일 뿐만 아니라 시험에서도 중요합니다. 시나리오와 요구 사항이 제시되며 가장 적합한 선택을 하는 것은 귀하에게 달려 있습니다. 이제 최적화 대상에 따라 가장 적합한 항목도 달라질 수 있습니다. 예를 들어, 운영 오버헤드를 최소화하도록 최적화하는 경우 마이그레이션을 위해 최소한의 재작업이 필요한 솔루션을 찾고 있는 경우와 다른 서비스를 선택할 수 있습니다. 시나리오를 고려하십시오. 회사에서 기존 백엔드 웹 서비스를 AWS로 마이그레이션하는 솔루션을 설계하고 있습니다. 애플리케이션은 현재 온프레미스 데이터 센터의 웹 서버에서 실행되고 있으며 회사는 가능한 한 최소한의 재작업으로 애플리케이션을 마이그레이션해야 합니다. 이를 위해 어떤 유형의 솔루션을 추천하시겠습니까? Amazon EC2에 대한 리프트 앤 시프트 솔루션에는 최소한의 노력이 필요합니다. 이는 웹 서비스가 현재 실행 중인 것과 동일한 운영 체제를 선택할 수 있으므로 재작업이 거의 필요하지 않기 때문입니다. 이것을 컨테이너 서비스 또는 AWS Lambda를 사용하여 이 웹 서비스를 호스팅하도록 선택하는 것과 비교하면 리프트 앤 시프트를 수행하는 데 최소한의 재작업이 필요합니다.

이와 같은 결정을 내리려면 각 컴퓨팅 서비스의 사용 사례에 대한 자세한 지식이 있어야 할 뿐만 아니라 작동 방식과 솔루션이 호스팅되는 방식에 대해서도 알고 있어야 합니다. AWS Lambda에서 호스팅되는 애플리케이션은 Amazon EC2에서 호스팅되는 애플리케이션과 다를 수 있습니다. 컴퓨팅 서비스 간의 차이점을 아는 것 외에도 각 서비스의 확장 메커니즘, 장애 조치 메커니즘 및 솔루션 설정 방법도 이해해야 합니다. 각 서비스에 대한 정확한 API 호출을 알 필요는 없지만 솔루션을 시작하고 실행하기 위한 일반적인 단계를 알고 있으면 됩니다. 조정의 경우 AWS와 함께 작업할 때 Amazon EC2 Auto Scaling의 단계별 작동 방식과 문제 해결 방법을 아는 것이 중요합니다. 다른 컴퓨팅 서비스의 경우 컨테이너 서비스에 대한 클러스터 확장과 AWS Lambda에 대한 동시성 비율을 이해해야 합니다.

다양한 컴퓨팅 서비스에 대한 이러한 수준의 깊이에 도달하면 시험과 실생활 모두에서 제공된 사용 사례에 가장 적합한 것을 선택할 수 있습니다. 그런 다음 한 단계 더 나아가 AWS 글로벌 인프라 내에서 고려 중인 컴퓨팅 서비스가 어디에 있는지 고려하십시오. 서비스를 사용하려면 AZ, 여러 AZ 또는 AWS 리전을 사용해야 합니까? AZ 또는 리전에서 애플리케이션 간의 통신을 어떻게 용이하게 할 수 있습니까? 이러한 유형의 질문에 대한 답변은 보고 있는 서비스에 따라 변경될 수 있습니다. 이것은 또한 컴퓨팅을 넘어 스토리지 및 데이터베이스 서비스까지 확장됩니다. 각 서비스는 특정 사용 사례를 염두에 두고 설계되었으며 사용 사례에 맞게 특별히 작성된 스토리지 또는 데이터베이스 서비스를 사용하면 해당 솔루션을 실행하는 데 필요한 작업을 단순화할 수 있습니다. 스토리지의 경우 저장하는 데이터 유형과 성능 요구 사항에 따라 선택하는 서비스가 결정되는 경우가 많습니다.

따라서 블록 스토리지용 서비스, 오브젝트 스토리지용 서비스, 파일 스토리지용 서비스가 무엇인지 알아야 합니다. 그런 다음 이러한 서비스가 데이터 읽기 및 쓰기 성능, 해당 데이터의 내구성 및 각 스토리지 서비스에 대한 데이터 백업 방법에 어떤 영향을 미치는지 확인하십시오. 예를 들어 EBS 볼륨 스냅샷을 만들고 관리하는 방법을 아는 것은 블록 스토리지 솔루션을 설정하는 데 중요한 부분입니다. 이 주제에 대해 잘 알고 있는지 확인하십시오. 각 스토리지 솔루션이 어떻게 설정되고 어떻게 작동하는지 자세히 알아보면 AWS에서 설계할 때 정보에 입각한 결정을 내리는 데 도움이 됩니다. 이제 데이터베이스와 관련하여 Amazon RDS용 읽기 전용 복제본, DynamoDB용 DynamoDB Accelerator 또는 Redis용 Amazon ElastiCache 또는 Memcached용으로 요청을 캐시로 오프로드하는 방법도 알아야 합니다. 읽기 전용 복제본의 경우 리전 또는 AZ 전체에서 읽기 전용 복제본을 허용하는 데이터베이스 엔진과 허용하지 않는 데이터베이스 엔진을 파악하십시오. 이것은 이 시험을 준비할 때 공부해야 하는 세부 수준입니다.

이제 네트워킹의 경우 다른 계층에 대해 설명한 것과 동일한 수준의 깊이에서 네트워킹을 이해하려고 노력해야 합니다. 즉, 각 네트워킹 서비스 또는 개념의 사용 사례, 네트워크 솔루션 설정 및 운영의 일반적인 단계, 장애 조치 및 재해 복구를 위한 다중 AZ 또는 다중 지역 배포와 같은 이점을 활용하여 문제를 완화하는 방법을 이해해야 합니다. . 이는 AWS 글로벌 인프라가 어떻게 설정되고 모든 것이 함께 작동하는지 실제로 연구한다는 것을 의미합니다. 예를 들어 일부 서비스는 엣지 로케이션에서 사용할 수 있고 다른 서비스는 사용할 수 없습니다. 인프라 관점에서 서비스의 범위를 알아야 합니다. 네트워킹은 복잡한 주제일 수 있지만 이 시험에서 도움이 될 뿐만 아니라 일반적으로 AWS에서 더 나은 솔루션을 이해하고 설계하는 데 도움이 될 것이기 때문에 기본 사항을 이해하기 위해 스스로 도전해야 합니다. 이는 Amazon Route 53, 생성할 수 있는 다양한 유형의 레코드, 다양한 라우팅 방법을 이해하고 Route 53에서 지역 장애 조치가 작동하는 방식을 알고 있음을 의미합니다.

그런 다음 VPC 생성 방법, 서브넷 생성 방법, 네트워크 액세스 제어 목록 또는 보안 그룹, 라우팅 테이블 사용, VPC에 연결할 수 있는 다양한 게이트웨이 사용 시기 및 방법 파악과 같은 VPC 관련 기능 및 서비스가 있습니다. 연결을 위해. 이제 연결에 대해 이야기하고 VPN 연결의 사용 사례를 아는 것과 Direct Connect와 Transit Gateway 또는 VPC 피어링과 같은 서비스를 사용하는 것 또한 중요합니다. 이는 하이브리드 또는 다중 계정 아키텍처를 설계하는 데 도움이 될 수 있습니다. 연결 측면에서도 AWS PrivateLink 및 VPC 엔드포인트를 이해하는 것이 좋습니다. 이는 AWS 기반 아키텍처의 또 다른 부분인 규정 준수 표준을 충족하는 솔루션을 선택하는 데 도움이 될 수 있습니다.

좋습니다. 여기에서 생각할 것이 많습니다. 그리고 결코 이 비디오가 당신이 공부해야 할 모든 것을 완벽하게 정리한 것은 아닙니다. 그러나 이것은 당신이 편안해야 하는 서비스의 범위와 깊이에 대한 아이디어를 제공해야 합니다. 그리고 AWS 설명서는 공부하는 동안 친구가 될 것임을 기억하십시오. 익숙하지 않거나 아직 사용하지 않은 서비스에 대해 읽고 있는지 확인하십시오.