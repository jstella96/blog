---
order: 22
icon: creative
title: 2-2 워크로드를 위한 확장 가능한 고성능 스토리지 솔루션 선택
category: 
  - Aws
tag: 
  - SAA-C02 자격증
editLink: false
---
Domain 2. 고성능 아키텍처 설계(Design High Performing Architectures) part 2
  
AWS-SAA 자격증 항목을 기준으로 AWS를 공부 합니다. 각 항목의 의미를 살펴보고 중점사항을 파악하는 것을 목표로 합니다.각 항목별 이론/실습으로 학습합니다.

::: details 상세 영역 ( 출처: aws certification 홈페이지 )

* 2.1 워크로드를 위한 탄력적이고 확장 가능한 컴퓨팅 솔루션 식별  
  * 컴퓨팅, 스토리지 및 네트워킹 요구 사항에 따라 적절한 인스턴스를 선택합니다.
  * 성능 요구 사항을 충족하도록 확장 가능한 적절한 아키텍처 및 서비스를 선택합니다.
  * 솔루션의 성능을 모니터링하는 지표를 식별합니다.

* 2.2 워크로드를 위한 확장 가능한 고성능 스토리지 솔루션 선택 👈👈👈👈👈 **지금 여기**
  * 성능 요구 사항을 충족하는 스토리지 서비스 및 구성을 선택합니다.
  * 향후 요구 사항을 수용하도록 확장 가능한 스토리지 서비스를 결정합니다.

* 2.3 워크로드를 위한 고성능 네트워킹 솔루션 선택
  * 성능 요구 사항을 충족하는 데 적절한 AWS 연결 옵션을 선택합니다.
  * AWS 퍼블릭 서비스에 대한 연결을 최적화하는 데 적절한 기능을 선택합니다.
  * 성능 이점을 제공하는 엣지 캐싱 전략을 결정합니다.
  * 마이그레이션 및/또는 수집에 적합한 데이터 전송 서비스를 선택합니다.

* 2.4 워크로드를 위한 고성능 데이터베이스 솔루션 선택
  * 적절한 데이터베이스 조정 전략을 선택합니다.
  * 성능 향상을 위해 데이터베이스 캐싱이 필요한 시점을 결정합니다.
  * 성능 요구 사항을 충족하는 적합한 데이터베이스 서비스를 선택합니다.

:::

## 주요관점

AWS에서 솔루션을 구축할 때 작업할 데이터를 저장하는 방법과 위치를 파악해야 할 가능성이 가장 큽니다. 이것은 간단한 작업처럼 보일 수 있지만 잠재적으로 요구 사항을 충족할 수 있는 다양한 AWS 스토리지 서비스가 있으며 올바른 것을 선택할 수 있으려면 연습이 필요합니다. 올바른 스토리지 솔루션을 선택하려면 솔루션이 확장되는 방식과 주어진 사용 사례에서 솔루션이 수행되는 방식을 평가하는 것이 포함됩니다. 예를 들어 Amazon EBS는 Amazon S3 또는 Amazon EFS와 같은 스토리지 솔루션과 완전히 다른 확장 메커니즘 및 성능 영향을 미칩니다.

- 향후 요구 사항을 수용하도록 확장 가능한 스토리지 서비스를 결정합니다

  - Amazon EBS를 파일 시스템의 스토리지로 사용하여 Amazon EC2 인스턴스에서 웹 애플리케이션을 호스팅한다고 가정해 보겠습니다. EBS 볼륨의 스토리지 용량이 부족해지기 시작하면 볼륨을 확장해야 합니다. 어떻게 합니까? 볼륨 크기를 변경해야 합니다. 이는 자동으로 발생하는 것이 아닙니다. 대신 이 수직적 확장이 일어나도록 조치를 취해야 합니다. 물론 이 작업은 자동화될 수 있지만 볼륨이 필요에 따라 더 많은 메모리를 추가하는 것은 서비스 기능에 내장된 것이 아닙니다. 이제 Amazon EFS를 사용하는 것과 비교해 보겠습니다. Amazon EFS에서 파일 시스템을 호스팅하고 있었고 스토리지를 한 번에 또는 다른 번에 수직으로 확장해야 할 것으로 예상되는 경우 해당 스토리지를 어떻게 확장할 수 있습니까? Amazon EBS의 경우처럼 수행해야 하는 작업입니까? 이 경우 Amazon EFS는 파일 시스템에서 파일을 추가하거나 제거할 때 자동으로 확장 및 축소됩니다.

  - 이러한 유형의 서비스 지식은 스토리지 확장에 필요한 운영 지원이 가장 적은 스토리지 솔루션을 선택하라는 시험에서 질문을 받는 경우에 유용할 수 있습니다. 또한 미래의 스토리지 요구 사항에 따라 어떤 스토리지 솔루션이 가장 적합한지 결정할 수 있어야 합니다. 데이터는 일반적으로 정적이지 않습니다. 시간이 지남에 따라 애플리케이션을 작동하면 데이터가 축적될 가능성이 가장 높으며 아키텍처 결정을 내릴 때 해당 데이터 축적 속도를 고려해야 합니다. 현재 3TB의 데이터 스토리지가 필요한 애플리케이션이 있지만 향후 5년 동안 100TB의 데이터 스토리지가 필요한 애플리케이션이 있다고 가정해 보겠습니다. 이것은 솔루션을 선택할 때 고려해야 할 사항입니다. 이는 또한 스토리지 솔루션의 용량에 대한 일반적인 상한을 알고 있어야 함을 의미합니다. 이는 향후 데이터 저장 요구 사항에 적합한 서비스를 선택하는 데 도움이 됩니다.

- 성능 요구 사항을 충족하는 스토리지 서비스 및 구성을 선택합니다.

  - 확장성 측면에서 AWS 스토리지 솔루션을 비교하는 것 외에도 성능을 기반으로 상황에 가장 적합한 솔루션을 결정할 수 있어야 합니다. 예를 들어 데이터를 처리하는 애플리케이션이 있고 이 애플리케이션은 데이터를 읽는 데 매우 짧은 대기 시간이 필요하다고 가정해 보겠습니다. 이 막연한 시나리오를 기반으로 짧은 대기 시간 요구 사항에 가장 적합한 AWS 스토리지 서비스를 생각해야 합니다. Amazon EBS 볼륨은 지연 시간이 매우 짧지만 성능 정도는 구성할 수 있습니다. 다양한 유형의 EBS 볼륨과 각 유형이 사용 사례 및 IOPS를 기반으로 하는 성능에 대해 잘 알고 있어야 합니다. EBS 볼륨에 대한 올바른 구성을 선택하면 성능에 큰 영향을 미칠 수 있으므로 솔루션을 설계할 때 이러한 구성을 인식하는 것이 중요합니다

  - 성능에 영향을 줄 수 있는 스토리지 서비스에 대한 구성이 많이 있으며 각 서비스의 주요 성능 구성에 대해 잘 알고 있어야 합니다.
    예를 들어 Amazon S3를 사용하여 솔루션을 설계할 때 데이터 업로드 또는 데이터 검색의 성능을 개선할 수 있는 방법을 고려하라는 요청을 받을 수 있습니다. 데이터 업로드 또는 전송의 경우 Amazon S3에 대한 기본 API 호출 또는 CLI 명령이 무엇인지 알고 있어야 하며 멀티파트 업로드 사용에 익숙해야 합니다. 또한 더 성능이 좋은 업로드를 위한 Amazon S3 Accelerator 또는 더 빠른 데이터 검색을 위한 Amazon CloudFront를 통한 캐싱과 같은 기능이 있어 설계 결정을 내리고 시험 문제에 답하는 데 도움이 될 수 있습니다.

공부할 때 다음 사항에 중점을 두어야 합니다. 현재 및 미래의 스토리지 요구 사항을 수용하도록 확장할 수 있는 사용할 스토리지 서비스를 결정할 수 있고 다양한 상황에서 성능 요구 사항을 충족하는 AWS 서비스 및 구성을 선택할 수 있습니다. 이러한 주제에 대해 자세히 알아보려면 AWS 설명서와 백서를 자세히 살펴보는 것이 좋습니다.

- 스터디
  S3
- Basic API calls
- Multipart uploads
- amazon S3 Accelerator : 리전끼리 사용할 때
- Caching with Amazon ClouldFront

엣지 로케이션
ClouldFront CDN이용.
리전과 다른개념,빠른제공위해 더 많이 만들려고 한다.

## 키워드


## Question 

솔루션 설계자는 Amazon S3 버킷에 업로드할 많은 수의 비디오 파일을 받았습니다. 파일 크기는 100~500MB입니다. 솔루션 설계자는 또한 실패한 업로드 시도를 쉽게 재개하기를 원합니다. 솔루션 설계자는 어떻게 최단 시간에 업로드를 수행해야 합니까?

A. 각 파일을 5MB 부분으로 분할합니다. 개별 부품을 업로드하고 S3 멀티파트 업로드를 사용하여 부품을 완전한 객체로 병합합니다.
B. AWS CLI를 사용하여 aws s3 cp 명령으로 개별 객체를 Amazon S3 버킷에 복사합니다.
C. Amazon S3 콘솔에서 Amazon S3 버킷을 선택합니다. S3 버킷을 업로드하고 항목을 버킷으로 끌어다 놓습니다.
D. SFTP 및 AWS Transfer Family를 사용하여 파일을 업로드합니다. 이제 질문과 응답을 검토할 수 있도록 일시 중지하겠습니다.

이 질문에 집중해야 할 부분은 1) 우리가 알고 있는 파일이 S3에 업로드되고 있다는 사실입니다. 2) 또한 100~500MB의 파일 크기를 제공합니다. 일반적으로 이와 같은 숫자나 세부사항이 제공될 때 주의를 기울입니다. 왜냐하면 이것이 파일 크기가 중요하다는 것을 의미할 가능성이 높기 때문입니다. 해결해야 할 문제는 3)솔루션 설계자가 실패한 업로드 시도를 쉽게 재개해야 한다는 것입니다. 마지막으로 4) 시간이 가장 적게 소요되는 솔루션을 묻는 질문입니다.

답은 B입니다. AWS CLI를 사용하여 aws s3 cp 명령으로 개별 객체를 Amazon S3 버킷에 복사합니다. 일반적으로 객체 크기가 100MB에 도달하면 단일 작업으로 객체를 업로드하는 대신 멀티파트 업로드 사용을 고려해야 합니다. 멀티파트 업로드를 사용하면 처리량이 향상될 수 있으며 네트워크 오류로 인해 다시 시작하는 개체를 빠르게 복구할 수도 있습니다. 실패한 업로드 시도를 쉽게 재개할 수 있다고 말했으며 멀티파트 업로드가 이를 도와줍니다. 이제 명령줄과 cp 명령을 사용하려는 이유는 aws s3 명령이 파일 크기에 따라 멀티파트 업로드 및 다운로드를 자동으로 수행하기 때문입니다. 즉, 이 옵션이 문제를 해결하고 명령줄이 이미 멀티파트 업로드 부분을 수행하기 때문에 해결하는 데 시간이 거의 걸리지 않습니다.

A는 각 파일을 5MB 부분으로 분할합니다. 개별 부품을 정상적으로 업로드하고 S3 멀티파트 업로드를 사용하여 부품을 완전한 객체로 병합합니다. S3의 멀티파트 업로드는 100MB를 초과하는 객체에 권장되기 때문에 이것은 올바르지 않습니다. 따라서 객체를 5MB 부분으로 분할할 필요가 없으며 업로드하기 전에 객체가 여러 부분으로 분할되었기 때문에 S3의 객체를 원래 크기로 재조립해야 합니다. 이것은 또한 cp 명령을 사용하는 것보다 더 많은 시간이 걸립니다.
C는 Amazon S3 콘솔에서 Amazon S3 버킷을 선택합니다. S3 버킷을 업로드하고 항목을 버킷으로 끌어다 놓습니다. 관리 콘솔에서 S3로 파일을 업로드하면 네트워크 문제로부터 보호되지 않거나 자동으로 멀티파트 업로드가 수행되지 않기 때문에 이것은 올바르지 않습니다. 따라서 이것은 줄기에 제시된 문제를 해결하지 못합니다.
D는 SFTP 및 AWS Transfer Family로 파일 업로드가 있습니다. 이 옵션은 SFTP를 통해 파일을 업로드할 수 있지만 파일 업로드를 쉽게 다시 시작하는 문제를 해결하지 못하기 때문에 올바르지 않습니다. 또한 이 옵션을 사용하려면 명령줄과 복사 명령을 사용하는 것보다 더 많은 작업과 시간이 필요합니다.
