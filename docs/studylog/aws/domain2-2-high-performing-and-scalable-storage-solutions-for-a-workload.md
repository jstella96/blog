---
order: 22
icon: creative
title: 2-2 워크로드를 위한 확장 가능한 고성능 스토리지 솔루션 선택
category: 
  - Aws
tag: 
  - SAA-C02 자격증
editLink: false
---

AWS-SAA 자격증 항목을 기준으로 AWS를 공부 합니다. 각 항목의 의미를 살펴보고 중점사항을 파악하는 것을 목표로 합니다.각 항목별 이론/실습으로 학습합니다.

::: details 상세 영역 ( 출처: aws certification 홈페이지 )

* 2.1 워크로드를 위한 탄력적이고 확장 가능한 컴퓨팅 솔루션 식별  
  * 컴퓨팅, 스토리지 및 네트워킹 요구 사항에 따라 적절한 인스턴스를 선택합니다.
  * 성능 요구 사항을 충족하도록 확장 가능한 적절한 아키텍처 및 서비스를 선택합니다.
  * 솔루션의 성능을 모니터링하는 지표를 식별합니다.

* 2.2 워크로드를 위한 확장 가능한 고성능 스토리지 솔루션 선택 👈👈👈👈👈 **지금 여기**
  * 성능 요구 사항을 충족하는 스토리지 서비스 및 구성을 선택합니다.
  * 향후 요구 사항을 수용하도록 확장 가능한 스토리지 서비스를 결정합니다.

* 2.3 워크로드를 위한 고성능 네트워킹 솔루션 선택
  * 성능 요구 사항을 충족하는 데 적절한 AWS 연결 옵션을 선택합니다.
  * AWS 퍼블릭 서비스에 대한 연결을 최적화하는 데 적절한 기능을 선택합니다.
  * 성능 이점을 제공하는 엣지 캐싱 전략을 결정합니다.
  * 마이그레이션 및/또는 수집에 적합한 데이터 전송 서비스를 선택합니다.

* 2.4 워크로드를 위한 고성능 데이터베이스 솔루션 선택
  * 적절한 데이터베이스 조정 전략을 선택합니다.
  * 성능 향상을 위해 데이터베이스 캐싱이 필요한 시점을 결정합니다.
  * 성능 요구 사항을 충족하는 적합한 데이터베이스 서비스를 선택합니다.

:::

## Domain 2 고성능 아키텍처 설계
## 워크로드를 위한 확장 가능한 고성능 스토리지 솔루션 선택


- 성능 요구 사항을 충족하는 스토리지 서비스 및 구성을 선택합니다.
  - 성능을 기반으로 상황에 가장 적합한 솔루션을 결정할 수 있어야 합니다. 특정 애플리케이션은 데이터를 읽는 데 매우 짧은 대기 시간이 필요하다고 가정 했을 때 가장 적합한 AWS 스토리지 서비스를 선택해야합니다. 다양한 유형의 EBS 볼륨과 각 유형이 사용 사례 및 IOPS를 기반으로 하는 성능에 대해 잘 알고 있어야 합니다. 
  - 성능에 영향을 줄 수 있는 스토리지 서비스에 대한 구성이 많이 있으며 각 서비스의 주요 구성에 대해 잘 알고 있어야 합니다. 데이터 업로드 또는 전송에  Amazon S3에 대한 기본 API 호출 또는 CLI 명령이 무엇인지,  멀티파트 업로드, 성능이 좋은 업로드를 위한 Amazon S3 Accelerator, 더 빠른 데이터 검색을 위한 Amazon CloudFront를 통한 캐싱과 같은 기능이 있을 알고 설계할 수 있어야 합니다.

- 향후 요구 사항을 수용하도록 확장 가능한 스토리지 서비스를 결정합니다
  -  EBS와 ECS의 적합한 사용 사례를 구분할 수 있는가? 만약 확장이 필요할 때 각 스토리지에 필요한 조치가 무엇이고 운영지원적인 면에서 무엇이 나은 선택인가?
  -   애플리케이션을 작동하면 데이터가 축적되어 간다. 스토리지 솔루션의 용량에 대한 일반적인 상한을 알고 있어야 한다. 

결론: 현재 및 미래의 스토리지 요구 사항을 수용하도록 확장할 수 있는 사용할 스토리지 서비스를 결정할 수 있고 다양한 상황에서 성능 요구 사항을 충족하는 AWS 서비스 및 구성을 선택할 수 있어야 한다.

## 키워드

::: tip 스토리지 상항선
스토리지 솔루션의 용량에 대한 일반적인 상한을 알고 있어야 한다. 
미래의 스토리지 요구 사항에 따라 어떤 스토리지 솔루션이 가장 적합한지 결정할 수 있어야 합니다. 데이터는 일반적으로 정적이지 않습니다. 시간이 지남에 따라 애플리케이션을 작동하면 데이터가 축적될 가능성이 가장 높으며 아키텍처 결정을 내릴 때 해당 데이터 축적 속도를 고려해야 합니다. 현재 3TB의 데이터 스토리지가 필요한 애플리케이션이 있지만 향후 5년 동안 100TB의 데이터 스토리지가 필요한 애플리케이션이 있다고 가정해 보겠습니다. 이것은 솔루션을 선택할 때 고려해야 할 사항입니다.  

:::

::: tip EBS 볼륨 유형 과 성능
EBS 볼륨과 각 유형이 사용 사례 및 IOPS를 기반으로 하는 성능
:::
::: tip EBS vs ECS 확장

  EBS : 자동 확장이 아님(따로 설정해야 한다)
  ECS : 자동 확장 및 축소
  
  ECS가 EBS보다 필요한 운영지원이 적다.

  Amazon EBS를 파일 시스템의 스토리지로 사용하여 Amazon EC2 인스턴스에서 웹 애플리케이션을 호스팅한다고 가정하면  EBS 볼륨의 스토리지 용량이 부족해지기 시작하면 볼륨을 확장해야 합니다. 이는 자동으로 발생하는 것이 아닙니다. 이 수직적 확장이 일어나도록 조치를 취해야 합니다. 물론 이 작업은 자동화될 수 있지만 볼륨이 필요에 따라 더 많은 메모리를 추가하는 것은 서비스 기능에 내장된 것이 아닙니다. 그러나 Amazon EFS는 다릅니다. Amazon EFS에서 파일 시스템을 호스팅하고 있었고 스토리지를 확장해야 할 것으로 예상되는 경우  Amazon EFS는 파일 시스템에서 파일을 추가하거나 제거할 때 자동으로 확장 및 축소됩니다.
  :::
  

:::tip S3 storage 서비스 구성 
- Basic API calls
- Multipart uploads
- amazon S3 Accelerator : 리전끼리 사용할 때
- Caching with Amazon ClouldFront

:::

:::tip ClouldFront CDN
엣지 로케이션
ClouldFront CDN이용
:::
## Question 

솔루션 설계자는 Amazon S3 버킷에 업로드할 많은 수의 비디오 파일을 받았습니다. 파일 크기는 100~500MB입니다. 솔루션 설계자는 또한 실패한 업로드 시도를 쉽게 재개하기를 원합니다. 솔루션 설계자는 어떻게 최단 시간에 업로드를 수행해야 합니까?

A. 각 파일을 5MB 부분으로 분할합니다. 개별 부품을 업로드하고 S3 멀티파트 업로드를 사용하여 부품을 완전한 객체로 병합합니다.  
B. AWS CLI를 사용하여 aws s3 cp 명령으로 개별 객체를 Amazon S3 버킷에 복사합니다.  
C. Amazon S3 콘솔에서 Amazon S3 버킷을 선택합니다. S3 버킷을 업로드하고 항목을 버킷으로 끌어다 놓습니다.  
D. SFTP 및 AWS Transfer Family를 사용하여 파일을 업로드합니다. 이제 질문과 응답을 검토할 수 있도록 일시 중지하겠습니다.

--- 

* 문제 분석
  1) 가지고 있는 파일이 S3에 업로드되야한다.
  2) 또한 100~500MB의 파일 크기를 제공합니다. 
  3) 솔루션 설계자가 실패한 업로드 시도를 쉽게 재개해야 합니다.
  4) 시간이 가장 적게 소요되는 솔루션을 선택해야 합니다.

* 정답 B  
  *  AWS CLI의  aws s3 cp 명령은 파일 크기에 따라 멀티파트 업로드 및 다운로드를 자동으로 수행하기 때문입니다. 일반적으로 객체 크기가 100MB에 도달하면 단일 작업으로 객체를 업로드하는 대신 멀티파트 업로드 사용을 고려해야 합니다. 멀티파트 업로드를 사용하면 처리량이 향상될 수 있으며 네트워크 오류로 인해 다시 시작하는 개체를 빠르게 복구할 수도 있습니다.

* 오답이유 
  * A. S3의 멀티파트 업로드는 100MB를 초과하는 객체에 권장되기 때문에 이것은 올바르지 않습니다. 따라서 객체를 5MB 부분으로 분할할 필요가 없으며 업로드하기 전에 객체가 여러 부분으로 분할되었기 때문에 S3의 객체를 원래 크기로 재조립해야 합니다. 이것은 cp 명령을 사용하는 것보다 더 많은 시간이 걸립니다.
  * C. Amazon S3 관리 콘솔에서 S3로 파일을 업로드하면 네트워크 문제로부터 보호되지 않거나 자동으로 멀티파트 업로드가 수행되지 않기 때문에 이것은 올바르지 않습니다.
  * D. SFTP를 통해 파일을 업로드할 수 있지만 파일 업로드를 쉽게 다시 시작하는 문제를 해결하지 못하기 때문에 올바르지 않습니다. 또한 이 옵션을 사용하려면 명령줄과 복사 명령을 사용하는 것보다 더 많은 작업과 시간이 필요합니다.
