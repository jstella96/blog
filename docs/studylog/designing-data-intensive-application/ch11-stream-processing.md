---
order: 11
icon: lock
title: 스트림처리
category:
  - IT서적
editLink: false
---

앞선 10장에서는 일괄처리를 살펴보았다. 일괄처리란 입력으로 파일 집합을 읽고 출력으로 새로운 파일 집합을 생성하는 기술이다. 출력은 파생데이터 이다.
일괄처리는 필요하다면 다시 수행해서 재생성이 가능한 데이터 셋이며, 검색색인이나 추천시스템, 분석 등에서 사용된다.
그러나 일괄처리는 입력을 사전에 알려진 유한한 크기로 가정한다는 가정이 있어야한다. 예를 들어 맵리듀스의 핵심인 정렬연산의 경우
출력을 시작하기전에 전체 입력을 다읽어야 한다. 키로 정렬한다고 했을 때 마지막 입력레코드가 가장 낮은 키라면 해당 레코드가 가장 마지막에 출력되어야 하기 때문이다. 조기 출력을 시작 할 수 없다.

그러나 실제 데이터는 오늘도 생산되고 내일도 생산된다. 데이터 셋은 절대 '완료'되지 않는다. 일괄처리 프로세서는 작업을 수행하기 위해 인위적으로 일정 기간씩 데이터 청크를 나눠야한다. 하루가 끝나는 시점에 하루데이터나 매시간이 끝날 때
해당 시간의 데이터를 처리하는 식으로 말이다.

일괄처리의 문제점은 입력의 변화가 시간이 지나야 반영이 된다는 것인데, 당연히 이방법을 사용하면 사용자가 느끼기에 너무 느리다. 이런지체를 줄이기 위해 고정된 시간조각이라는 개념을 완전히 버리고
단순히 이벤트가 발생할 때마다 처리하는 개념이 **스트림 처리**의 기본 개념이다.
일반적으로 스트림은 시간 흐름에 따라 점진적으로 생산된 데이터를 일컫는다. 이번 장에서는 데이터 관리 메커니즘인 이벤트 스트림을 다루게 되는데 **일괄처리의 데이터는 입력이 한정적으로 이벤트 스트림 데이터는 점진적으로 처리된다**

## 이벤트 스트림 전송

스트림 처리에서 입출력은 입력이 파일(바이트의 연속)일 때 대개 첫 번째 단계로 파일을 분석해 레코드의 연속으로 바꾸는 처리를 한다. 스트림 처리 문맥에서 레코드를 보통 이벤트라고 하지만 특정 시점에 일어난 사건에 대한 세부 사항을 포함하는, 작고 독립된 불변 객체라는 점에서 동일하다. 일반적으로 발생 타임스탬프를 포함한다. 예를 들어 웹페이지를 보거나 상품을 구입하는 일같은 사용자가 취한 행동이 이벤트가 될 수 있다. 일괄처리에서 파일을 한 번 기록하면 여러 작업에서 읽을 수
있었듯이 스트리밍에서도 이와 비슷하다 생산자(producer)가 이벤트를 한 번 만들면 해당 이벤트를 복수의 소비자(consumer)가 처리 할 수 있다.

이론상으로는 파일이나 데이터베이스가 있으면 생산자와 소비자를 연결하기에 충분하다. 생산자는 데이터스토어에 기록하고 소비자는 주기적으로 폴링해 마지막으로 처리한 이벤트 이후에 새로 발생한 이벤트가 있는지 확인하는 방법이다. 그러나 지연 시간이 낮으면서 지속해서 처리하는 방식을 지향할 때 데이터스토어를 이런 용도에 맞게 설계하지 않았다면 폴링 방식은 비용이 크다. 폴링이 잦을 수록 새로운 이벤트 반환 요청 비율이 낮아져서 오버헤드가 커진다. 오히려 새로운 이벤트가 나타날 때 마다 소비자에게 알리는 편이 낮다. 그러나 데이터 베이스는 전통적으로 알림 메커니즘을 강력하게 지원하지 않는다. 보통 관계형 데이터베이스에는 트리거 기능이 있지만 기능이 제한적이고 데이터베이스를 설계한 이후에 도입한 개념이다.
대신 이벤트 알림 전달 목적으로 개발된 특별한 도구들이 있다.

## 메시징 시스템

새로운 이벤트에 대해 소비자에게 알려주기 위해 쓰이는 일반적인 방법은 메시징 시스템을 사용하는 것이다. 생산자는 이벤트를 포함한 메시지를 전송한다. 그리고 메시지는 소비자에게 전달된다.
메세징 시스템은 다수의 생산자 노드가 같은 토픽으로 메시지를 전송할 수 있고 다수의 소비자 노드가 토픽하나에서 메시지를 받아갈 수 있다.

발행/구독(publish/subscribe) 모델에서는 여러 시스템들이 다양한 접근법을 사용한다. 모든 목적에 부합하는 하나의 정답은 없기 때문에 아래 두가지 질문에 시스템을 구별하는 데 상당히 도움이 된다.

1. 생산자가 소비자가 메시지를 처리하는 속도보다 빠르게 메시지를 전송한다면 어떻게 될까? 시스템은 메시지를 버리거나 큐에 버퍼링 하거나 흐름을 제어하여 생산자가 메시지를 더 보내지 못하게 막는다.

2. 노드가 죽거나 일시적으로 오프라인이 된다면 어떻게 될까? 손실되는 메시지가 생길까? 데이터베이스를 사용할 때처럼 지속성을 갖추려면 디스크에 기록하거나 복제 본 생성을 해야 한다. 그렇기 때문에 비용이 든다. 때로는 메세지를 잃어도 괜찮다면 처리량을 높이고 지연시간을 낮출 수 있다.

메시지의 유실을 허용하지 말지는 애플리케이션에 따라 상당히 다르다. 주기적으로 생성되는 센서값은 가끔 데이터가 누락되더라도 큰 문제가 없을 수 있지만 이벤트 수를 세는 경우 메시지가 유실됐다는 것은 카운터가 잘못됐다는 의미이기 때문에 메시지를 신뢰성 있게 전송하는 일은 매우 중요하다.

## 메시지 브로커

직접 메시징 시스템은 설계 상황에서는 잘 동작하지만 일반적으로 메시지가 유실될 수 있는 가능성을 고려해서 애플리케이션 코드를 작성해야 한다. 허용 가능한 결함은 상당히 제한적이다. 프로토콜이 네트워크 상에서 패킷 유실을 감지하고 재전송을 하더라도 소비자가 오프라인이라면 메시지를 전달하지 못하는 상태에 있는 동안 전송된 메시지는 잃어버릴 수 있다.

직접 메시징 시스템의 대안으로 사용되는 방법은 메시지 브로커(메시지 큐)를 통해 메시지를 보내는 것이다. 메시지 브로커는 근본적으로 메시지 스트림을 처리하는 데 최적화된 데이터베이스의 일종이다. 서버로 구동되고 생산자와 소비자는 서버의 클라이언트로 접속한다.
브로커에 데이터가 모이기 때문에 이 시스템은 클라이언트의 상태 변경에 쉽게 대처할 수 있다. 지속성 문제가 브로커로 옮겨갔기 때문이다. 메시지 브로커는 메시지를 메모리에만 보관하거나 장애로 중단됐을 때도 메시지를 잃어버리지 않기 위해 디스크에 기록한다. 소비 속도가 느린 소비자가 있으면 일반적으로 브로커는 큐가 제한 없이 계속 늘어나게 한다. 이런 설정은 선택 가능 할 수도 있다.

또한 큐 대기를 하면 소비자는 일반적으로 비동기로 동작한다. 생산자가 메시지를 보낼 때 생산자는 메시지를 버퍼에 넣었는지 만 확인하고 처리하기까지 기다리지 않는다.

- 복수 소비자
  복수 소비자가 같은 토픽에서 메시지를 읽을 때 사용하는 두가지 주요 패턴이 있다.

1. 로드 밸런싱 : 각 메시지는 소비자 중 하나로 전달된다. 소비자는 해당 토픽의 메시지를 처리하는 작업을 공유한다.

2. 팬 아웃 : 각 메시지는 모든 소비자에게 전달된다. 여러 독립적인 소비자가 브로드 캐스팅된 동일한 메시지를 서로 간섭 없이 청취할 수 있다. 같은 입력 파일을 읽어 여러 다른 일괄 처리 작업에서 사용하는 것과 동일하다.

이 두가지 패턴은 함께 사용 가능하다. 예를 들어 두개의 소비자 그룹에서 하나의 토픽을 구독하고 각 그룹은 모든 메시지를 받지만 그룹내에서는 각 메시지를 하나의 노드만 받게 하는 식이다

- 확인 응답과 재전송

소비자는 언제라도 장애가 발생할 수 있다. 메시지를 잃어버리지 않기 위해 메시지 브로커는 확인 응답을 사용한다. 메시지 처리가 끝났을 때 브로커가 메시지를 큐에서 제거할 수 있게 명시적으로 알려야 한다. 브로커가 확인 응답을 받기전에 클라이언트로의 연결이 닫히거나 타임아웃되면 브로커는 메시지가 처리되지 않았다고 가정하고 다른 소비자에게 다시 전송한다. 부하 균형 분산과 결합할 때 이런 재전송 행위는 메시지 순서에 영향을 미친다. 메시지 브로커는 메시지 순서를 유지하려 노력할지라도 부하 균형 분산과 메시지 재전송을 조합하면 필연적으로 메시지 순서가 변경된다. 소비자 마다 독립된 큐를 사용하면, 즉 부하균형 분산 기능을 사용하지 않는다면 이문제를 피할 수 있다.
메시지가 서로 완전히 독립이라면 메시지 순서가 바뀌는 것은 문제가 되지 않지만 메시지 간 인과성이 있다면 이것은 매우 중요한 문제이다.

---

## 파티셔닝 된 로그

브로커는 메세지를 일시적으로 보관하는 개념으로 만들졌다. AMQP/JMS형식의 메세지 형식은 브로커가 확인 응답을 받으면 브로커에서 메세지를 삭제하기 때문에 소비자가 재실행을 해도 동일한 결과를 받지 못하고 시스템에 새로운 소비자를 추가하면 일반적으로 소비자를 등록한 시점 이후에 전송된 메시지부터 받기 시작한다. 이전 메시지는 한번 지나가면 다시 복구할 수 없다. 파일시스템, 데이터 베이스는 이와 반대다. 과거의 기록했던 데이터도 애플리케이션이 명시적으로 지우거나 덮어쓰지 않은면 얼마든지 읽을 수 있다.
데이터베이스의 지속성 있는 저장 방법과 메시징 시스템의 지연 시간이 짧은 알림 기능을 조합하는 것이 **로그 기반 메시지 브로커**의 기본 아이디어다.

## 로그를 사용한 메시지 저장소

로그는 단순히 디스크에 저장된 추가 전용 레코드의 연속이다. 브로커를 구현할 때도 같은 구조를 사용한다. 생산자가 보낸 메시지는 로그 끝에 추가하고 소비자는 로그를 순차적으로 읽어 메시지를 받는다. 로그 끝에 도달하면 새 메시지가 추가됐다는 알림을 기다린다. 디스크 하나를 쓸 때보다 처리량을 높이기 위해 확장하는 방법으로 로그를 파티셔닝하는 방법이 있다. 각 파티션은 다른 파티션과 독립적으로 읽고 쓰기가 가능한 분리된 로그가 된다. 토픽은 같은 형식의 메시지를 전달하는 파티션들의 그룹으로 정이ㅢ한다. 각 파티션 내에는 브로커는 모든 메시지에 offset의 단조 증가하는 순번을 부여한다. 파티션 내 전체 메시지는 전체 순서가 있기 때문에 순번을 부여하는 것은 타당하다. 단 다른 파티션간 메시지 순ㄱ서는 보장하지 않는다.

아파치 카프카가 이런 방식으로 동작하는 로그 기반 메시지 브로커다. 이런 메시지 브로커는 모든 메시지를 디스크에 저장하지만 여러 장비에 메시지를 파티셔닝해 초당 수백만 개의 메시지를 처리할 수 있고 메시지를 복제함으로써 장애에 대비할 수 있다.

- 로그 방식과 전통적인 메시징 방식의 비교

메시지를 처리하는 비용이 비싸고 메시지 단위로 병렬화 처리하고 싶지만 메시지 순서는 중요하지 않다면 AMQP/JMS 방식의 메시지 브로커가 적합하다. 반면 처리량이 많고 메시지를 처리하는 속도가 빠르지만 메시지 순서가 중요하다면 로그 기반 접근법이 효과적이다.

- 소비자 오프셋
  파티션 하나를 순서대로 처리하면 메시지를 어디까지 처리했는지 알기 쉽다. 소비자의 현재 오프셋보다 작은 오프셋을 가진 메시지는 이미 처리한 메시지고 소비자의 현재 오프셋보다 큰 오프셋을 가진 메시지는 아직 처리하지 않은 메시지다. 따라서 브로커는 모든 개별 메시지마다 보내는 확인 응답을 추적할 필요가 없다. 주기적으로 소비자 오프셋을 기록하면 된다. 추적 오버헤드가 감소하고 일괄 처리와 파이프라이닝을 수행할 수 있는 기회를 제공해 로그 기반 시스템의 처리량을 늘리는 데 도움을 준다.
  소비자 노드에 장애가 발생하면 소비자 그룹 내 다른 노드에 장애가 발생한 소비자의 파티션을 할당하고 마지막 기록된 오프셋부터 메시지를 처리하기 시작한다.

- 디스크 공간 사용

디스크 공간을 재사용하기 위해 실제로는 로그를 여러 조각으로 나누고 가끔 오래된 조각을 삭제하거나 보관 저장소로 이동한다. 소비자 처리 속도가 느려 메시지가 생산되는 속도를 따라잡지 못하면 소비자 오프셋이 이미 삭제한 조각을 가리킬 수도 있다. 즉 메시지 일부를 잃어버릴 가능성이 있다. 로그를 크기가 제한된 버퍼로 구현하고 버퍼가 가득차면 오래된 메시지 순서대로 버린다 이런 버퍼를 원형 버퍼, 링 버퍼라고한다. 버퍼가 디스크상에 있다면 상당히 커질 수 있다.
이런 로그 기반의 경우 모든 메시지를 디스크에 기록하기 때문에 로그 처리량은 일정하다. 메시징 시스템의 경우는 기본적으로 메모리에 메시지를 유지하고 큐가 커질때만 디스크에 기록하기 때문에 큐가 작을 때는 빠르지만 디스크에 기록하기 시작하면 매우 느려진다. 시스템 처리량이 보유한 메시지에 따라 다르다.

- 소비자가 생산자를 따라갈 수 없을 때

소비자가 뒤처져 필요한 메시지가 디스크에 보유한 메시지보다 오래되면 필요한 메시지는 읽을 수 없다. 그래서 브로커는 버퍼 크기를 넘는 오래된 메시지를 자연스럽게 버린다. 버퍼가 커질수록, 사람이 소비자 처리가 느린 문제를 고쳐 메시지를 잃기 전에 따라잡을 시간을 충분히 벌 수 있다.

- 오래된 메시지 재생

AMQP같은 인메모리 유형의 메시지 브로커에서는 처리하고 확인 응답하는 작업은 메시지를 제거하기 때문에 파괴적 연산이다. 반면 로그 기반 메시지 브로커는 메시지를 소비하는 게 오히려 파일을 읽는 작업과 더 유사하다. 로그를 변화시키지 않는 읽기전용 연산이기 때문이다. 소비자 오프셋은 ㅈ소비자 관리 아래에 있다. 그래서 필요하다면 쉽게 조작할 수 있다 어제의 오프셋을 복사했다가 재처리 할 수 있다.

## 데이터 베이스와 스트림

이종 데이터 시스템에서 발생하는 문제 한가지를 먼저 살펴본 다음 이벤트 스트림의 아이디어를 데이터 베이스에 적용해 이 문제를 해결하는 방법을 찾아보자.

- 시스템 동기화 유지하기

실제로 대부분의 중요 애플리케이션이 요구사항을 만족하기 위해서는 몇가지 다른 기술의 조합이 필요하다.
사용자 요청에 대응하기 위한 OLTP 데이터베이스, 공통 요청의 응답 속도를 높이기 위한 캐시, 검색 질의를 다루기 위한 전문 색인, 분석용 데이터 웨어하우스가 그 예다. 이 시스템 각각은 데이터의 복제본을 가지고 있고 그 데이터는 목적에 맞게 최적화된 형태로 각각 저장된다. 관련이 있거나 동일한 데이터가 여러 다른 장소에서 나타나기 때문에 이시스템들은 서로 동기화가 필수다.

주기적으로 데이터베이스 전체를 덤프하는 작업이 너무 느리면 대안으로 사용하는 방법으로 이중 기록이 있다. 데이터가 변할 때마다 애플리케이션 코드에서 명시적으로 각 시스템에 기록한다. 경쟁조건의 문제와, 한쪽의 쓰기 실패의 경우로 불일치가 발생하는 현상이 발생한다.

- 변경 데이터 캡쳐

최근 들어 변경 데이터 캡쳐(CDC)에 관심이 높아지고 있다. 데이터베이스에 기록하는 모든 데이터의 변화를 관찰해 다른 시스템으로 데이터를 복제할 수 있는 형태로 추출하는 과정이다. 변경 내용을 스트림으로 제공할 수 있으면 특히 유용하다.
예를 들면 데이터 베이스의 변경사항을 캡쳐해 검색색인에 꾸준히 반영할 수 있다. 다른 파생 데이터ㅏ 시스템도 단지 변경스트림의 소비자로 만들 수 있다.
데이터 베이스에 쓰여진 순서대로 데이터를 가져와 다른 시스템에 변경사항을 같은 순서로 적용한다.

- 변경 데이터 캡처의 구현
  를 나타낸다. 변경 로그를 지속성 있게 저장한다면 상태를 간단히 재생성할 수 있는 효과가 있다. 이벤트 로그를 레코드 시스템으로 생각하고 모든 변경 가능 상태를 이벤트 로그로부터 파생된 것으로 생각하면 시스템을 거치는 데이터 흐름에 관해 추론하기 쉽다.
  데이터베이스에 잘못된 데이터를 기록했을 때 코드가 데이터를 덮어썼다면 복구하기가 매우 어렵다. 추가만 하는 불변 이벤트 로그를 썼다면 문제 상황의 진단과 복구가 훨씬 쉽다.
  또한 불변 이벤트는 현재 상태보다 훨씬 많은 정보를 포함한다. 예를 들어 쇼핑웹사이트에서 고객이 장바구니에 항목하나를 넣었다가 제거했다고 하자 데이터 베이스에서는 잃어버리는 정보지만 이 이벤트 로그로는 남게 된다. 이것은 분석가에게 있어서는 중요한 정보다.

불변 이벤트 로그에서 가변 상태를 분리하면 동일한 이벤트 로그로 다른 여러 읽기 전용 뷰를 만들 수 있다.
일반적으로 데이터에 어떻게 질의하고 접근하는지 신경 쓰지 않는다면 데이터 저장은 상당히 직관적인 작업이다. 스키마 설계, 색인, 저장소 엔진이 가진 복잡성은 특정 질의와 특정 접근 형식을 지원하기 위한 결과로 발생한다. 이런 이유로 데이터를 쓰는 형식과 읽는 형식을 분리해 다양한 읽기 뷰를 허용한다면 상당한 유연성을 얻을 수 있다.

동시성 제어의 입장에서 보면 이벤트 소싱과 변경 데이터 캡처의 가장 큰 단점은 이벤트 로그의 소비가 대개 비동기로 이뤄진다는 점이다. 사용자가 로그에 이벤트를 기록하고 이어서 파생된 뷰를 읽어도 기록한 이벤트가 아직 뷰에 반영되지 않았을 가능성이 있다. 앞선 5장 복제 파트에서 이 문제를 설명했다.

영구적으로 모든 변화의 불변 히스토리를 유지하는 것이 어느 정도까지 가능할까? 대부분은 데이터를 추가하는 작업이고 갱신이나 삭제는 드물게 발생하는 작업부하는 불변으로 만들기 쉽다. 상대적으로 작은 데이터셋에서 매우 빈번히 갱신과 삭제를 하는 작업부하는 불변 히스토리가 감당하기 힘들 정도로 커지거나 파편화 문제가 발생할 수 있다.

성능적인 이유 외에도 개인정보 규제 등의 관리상의 이유로 데이터를 삭제할 필요가 있는 상황일 수 있다. 이런 상황에서는 이전데이터를 삭제해야한다는 이벤트를 추가해서 해결되는 경우가 아니다. 실제로 원하는 바는 히스토리를 새로 쓰고 문제가 되는 데이터를 처음부터 기록하지 않았던 것처럼 하는 일이다. 이 기능을 적출(exicision)이라고 부른다.
데이터를 진짜로 삭제하는 작업은 어렵다. 많은 곳에 복제본이 남아 있기 때문이다.

## 스트림 처리

지금까지 스트림이 어디에서 오는지 스트림이 어떻게 전송되는지 살펴봤다. 그렇다면 스트림으로 할 수 있는 일은 무엇이 있을까?

스트림을 처리하는 방법에는 크게 세 가지 방법이 있다.

1. 이벤트에서 데이터를 꺼내 유사한 저장소 시스템에 기록하고 다른 클라이언트가 이 시스템에 해당 데이터를 질의한다.
   검색 색인과 데이터 웨어하우스에 저장된 데이터는 레코드 시스템에 저장된 데이터의 또 다른 뷰일 뿐인 파생 데이터 시스템이라 할 수 있다. 변경 데이터 캡처는 파생 데이터 시스템이 레코드 시스템의 정확한 데이터 복제본을 가지게 하기 위해 레코드 시스템에 발생하는 모든 변경 사항을 파생 데이터 시스템에 반영하는 것을 보장하는 메커니즘이다.
   변경 데이터 캡쳐는 본질적으로 변경사항을 캡처할 데이터 베이스 하나를 리더로 하고 나머지를 팔로워로 한다.
   로그기반 메시지 브로커는 메시지 순서를 유지하기 때문에 원본 데이터베이스에서 변경 이벤트를 전송하기에 적합하다.
   변경 데이터 캡처는 메시지 브로커와 동일하게 비동기 방식으로 동작한다. 데이터베이스 시스템은 변경 사항을 커밋하기 전에 변경 사항이 소비자에게 적용될 때까지 기다리지 않는다.

- 로그 컴팩션

로그 히스토리 양을 제한 한다면 새로운 파생데이터 시스템을 추가할 때마다 스냅숏을 만들어야 하지만 로그 컴팩션이라는 대안이 있다.
저장 엔진은 주기적으로 같은 키의 로그 레코드를 찾아 중복을 제거하고 각 키에 대해 가장 최근에 갱신된 내용만 유지하는 컴팩션. 컴팩션과 병학 과정은 백그라운드로 실행된다. CDC 시스템에서 모든 변경에 기본키가 포함되게 하고 키의 모든 갱신이 해당 키의 이전 값을 교체한다면 특정 키에 대해 최신 쓰기만 유지하면 충분하다.
로그에 데이터베이스에 있는 모든 키의 최신 값이 존재하는 것이 보장된다. CDC 원본 데이터베이스의 스냅숏을 만들지 않고도 데이터베이스 콘텐츠 전체의 복사본을 얻을 수 있다.
아파치 카프카는 로그 컴팩션 기능을 제공한다. 메시지 브로커는 일시적 메시징뿐만 아니라 지속성 있는 저장소로도 사용 가능하다.

- 이벤트 소싱(sourcing)

이벤트 소싱은 도메인 주도 설계 커뮤니티에서 개발한 기법이다. 스트리밍 시스템에 관련한 유용한 아이디어를 포함한다. 변경 데이터 캡처와 유사하게 애플리케이션 상태 변화를 모두 변경 이벤트 로그로 저장한다. 큰 차이점은 이 아이디어를 적용하는 추상화 레벨이 다르다는 점.

데이터 모델링에 쓸 수 있는 강력한 기법이다. 애플리케이션 관점에서 사용자의 행동을 분변 이벤트로 기록하는 방식은 변경 가능한 데이터베이스 상에서 사용자의 행동에 따른 효과를 기록하는 방식보다 훨씬 유의미하다.
이벤트 소싱은 연대기 데이터 모델과 유사하다. 또한 이벤트 로그와 별 모양 스키마에서 발견한 사실 테이블 사이에도 유사점이 있다. 이벤트 스토어 같은 특화된 데이터베이스는 이벤트 소싱을 사용하는 애플리케이션을 지원하게끔 개발한다.

이벤트 로그 그 자체로는 유용하지 않다. 사용자는 시스템의 현재 상태를 보기를 원하지 수정 히스토리를 원하지 않기 때문이다. 따라서 이벤트 소싱을 사용하는 애플리케이션은 시스템에 기록한 데이터를 표현한 이벤트 로그를 가져와 사용자에게 보여주기에 적당한 애플리케이션 상태로 변환해야 한다. 결정적 과정이어야 한다. 다시 수행하더라도 이벤트 로그로부터 동일한 애플리케이션 상태를 만들 수 있어야 하기 때문이다.
변경 데이터 캡처와 마찬가지로 이벤트 로그를 재현하면 현재 시스템 상태를 재구성할 수 있다. 하지만 로그 컴팩션은 다르게 처리해야 한다. 사용자의 행동의 결과로 발생한 상태 갱신 메커니즘이 아닌 사용자 행동 의도를 표현해야 한다.

이벤트 소싱 철학은 이벤트와 명령을 구분하는 데 주의한다. 사용자 요청이 처음 도착했을 때 이 요청은 명령이다. 이 시점에서 실패할 수도 있다. 이벤트는 생성 시점에 사실이 된다. 사용자가 나중에 예약을 변경하거나 취소하더라도 그 사실은 여전히 진실이며 변경이나 취소는 나중에 추가된 독립적인 이벤트다. 따라서 명령의 유효성은 이벤트가 되기 전에 동기식으로 검증해야 한다. 예를 들어 하나는 가예약 이벤트, 다른 하나는 유효한 예약에 대한 확정 이벤트다. 분할해서 비동기 처리로 유효성 검사를 할 수 있다.

## 상태와 스트림 그리고 불변성

불변성에 원리가 이벤트 소싱과 변경데이터 캡쳐를 매우 강력하기 만든다. 모든 변경 로그는 시간이 지남에 따라 바뀌는 상태

2, 이벤트를 사용자에 직접 보낸다. 경고, 푸시, 메일 같은 것.

3. 하나 이상의 입력 스트림을 처리해 하나 이상의 파생 스트림을 생산한다. 최종 출력에 (1, 2)에 이르기까지 여러 처리 단계로 구성된 파이프라인을 통과할 수도 있다.

위의 3번의 영역에는 이벤트 패턴 검색, 스트림 분석을 통한 집계 연산, 파생 데이터의 최신성 유지등의 사용영역이있다.

## 정리

- AMQP/JMS 스타일 메시지 브로커
  브로커는 개별 메시지를 소비자에게 할당하고 소비자는 받은 메시지를 처리하는 데 성공하면 확인 응답을 보낸다. 확인 응답을 받은 메시지는 삭제된다. RPC와 같은 비동기 양식에 적절하다. 메시지의 처리가 정확한 순서대로 이뤄지는 것이 중요하지 않고 메시지가 처리된 후에 이전으로 돌아가 과거 메시지를 다시 읽을 필요가 없다.

- 로그 기반 메시지 브로커
  브로커는 한 파티션 내의 모든 메시지를 동일한 소비자 노드에게 할당하고 항상 같은 순서로 메시지를 전달한다. 병렬화는 파티션을 나누는 방식으로 사용한다. 소비자는 최근에 처리한 메시지의 오프셋을 체크포인트로 남겨 진행 상황을 추적한다. 브로커는 메시지를 디스크에 유지하기 때문에 필요한 경우 뒤로 돌아가 이전 메시지를 다시 읽을 수 있다.

사용자 활동 이벤트, 주기적인 센서 판독 값, 데이터 피드(ex.금융시장 데이터)는 자연스럽게 스트림으로 표현할 수 있다.  
암묵적으로 변경 데이터 캡처(CDC)를 통하거나 명시적으로 이벤트 소싱을 통해 변경 로그를 캡처할 수 있다. 로그 컴팩션을 사용하면 스트림에서 데이터베이스 내용의 전체 사본을 유지할 수 있다.

데이터베이스를 스트림처럼 표현하면 여러 시스템을 손쉽게 통합하는 기회가 열린다. 변경 로그를 소비해 그 로그를 파생 시스템에 적용하면 색인, 캐시, 분석용 시스템과 같은 파생 데이터 시스템을 항상 최신 상태로 유지할 수 있다. 처음부터 시작해 현재까지 모든 변경 로그를 소비하면 기존 데이터의 새로운 뷰를 구성하는 것도 가능하다.

상태를 스트림 형태로 유지하고 메시지를 재생하는 기능은 다양한 스트림 처리 프레임워크에서 스트림을 조인하거나 내결함성을 확보하기 위한 기술의 기초다. 포함한 스트림 처리의 목적에는
이벤트 패턴 검색, 윈도우 집계 연산, 파생 데이터 최신성 유지 등이 있다.
